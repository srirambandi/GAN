{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirambandi/GAN/blob/master/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RTzsFdfJn69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "792e685a-eea9-4236-a2ce-e8d42821cab5"
      },
      "source": [
        "# when running in colab notebooks, first install library\n",
        "!pip install import-ai\n",
        "# upload respective dataset manually from examples directory of the library or download as below\n",
        "!apt install subversion\n",
        "!svn checkout https://github.com/srirambandi/ai/trunk/examples/MNIST"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import-ai\n",
            "  Downloading https://files.pythonhosted.org/packages/16/c9/61a99b75a3ccd70ddd207ea12e28b9baa17feba9fffb2d7181d03d1b8147/import_ai-1.3.11-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.6/dist-packages (from import-ai) (1.18.5)\n",
            "Collecting graphviz>=0.14\n",
            "  Downloading https://files.pythonhosted.org/packages/83/cc/c62100906d30f95d46451c15eb407da7db201e30f42008f3643945910373/graphviz-0.14-py2.py3-none-any.whl\n",
            "Installing collected packages: graphviz, import-ai\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.14 import-ai-1.3.11\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libapr1 libaprutil1 libserf-1-1 libsvn1\n",
            "Suggested packages:\n",
            "  db5.3-util libapache2-mod-svn subversion-tools\n",
            "The following NEW packages will be installed:\n",
            "  libapr1 libaprutil1 libserf-1-1 libsvn1 subversion\n",
            "0 upgraded, 5 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 2,237 kB of archives.\n",
            "After this operation, 9,910 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libapr1 amd64 1.6.3-2 [90.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libaprutil1 amd64 1.6.1-2 [84.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libserf-1-1 amd64 1.3.9-6 [44.4 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsvn1 amd64 1.9.7-4ubuntu1 [1,183 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 subversion amd64 1.9.7-4ubuntu1 [834 kB]\n",
            "Fetched 2,237 kB in 1s (2,389 kB/s)\n",
            "Selecting previously unselected package libapr1:amd64.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../libapr1_1.6.3-2_amd64.deb ...\n",
            "Unpacking libapr1:amd64 (1.6.3-2) ...\n",
            "Selecting previously unselected package libaprutil1:amd64.\n",
            "Preparing to unpack .../libaprutil1_1.6.1-2_amd64.deb ...\n",
            "Unpacking libaprutil1:amd64 (1.6.1-2) ...\n",
            "Selecting previously unselected package libserf-1-1:amd64.\n",
            "Preparing to unpack .../libserf-1-1_1.3.9-6_amd64.deb ...\n",
            "Unpacking libserf-1-1:amd64 (1.3.9-6) ...\n",
            "Selecting previously unselected package libsvn1:amd64.\n",
            "Preparing to unpack .../libsvn1_1.9.7-4ubuntu1_amd64.deb ...\n",
            "Unpacking libsvn1:amd64 (1.9.7-4ubuntu1) ...\n",
            "Selecting previously unselected package subversion.\n",
            "Preparing to unpack .../subversion_1.9.7-4ubuntu1_amd64.deb ...\n",
            "Unpacking subversion (1.9.7-4ubuntu1) ...\n",
            "Setting up libapr1:amd64 (1.6.3-2) ...\n",
            "Setting up libaprutil1:amd64 (1.6.1-2) ...\n",
            "Setting up libserf-1-1:amd64 (1.3.9-6) ...\n",
            "Setting up libsvn1:amd64 (1.9.7-4ubuntu1) ...\n",
            "Setting up subversion (1.9.7-4ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "A    MNIST/test.npy\n",
            "A    MNIST/train.npy\n",
            "Checked out revision 120.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW4HapEUesLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3441dd6d-398f-47fa-b192-46fc06a25a22"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY0FMFMLJlgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ai\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNYfGAkfJlgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_dim = 100\n",
        "gf_dim = 64\n",
        "df_dim = 64"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiFy00xkJ3X1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ai.manual_seed(2357)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ3zS_s-Jlgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(m):\n",
        "    train_dict = np.load('MNIST/train.npy', allow_pickle=True)\n",
        "    test_dict = np.load('MNIST/test.npy', allow_pickle=True)\n",
        "    data = np.concatenate([train_dict.item()['data'], test_dict.item()['data']])\n",
        "    data = data.transpose(1, 2, 0)   # making data batch-last\n",
        "    data = data.reshape(1, *data.shape) / 255   # adding channel dimension and normalizing data\n",
        "    epoch = 0\n",
        "    \n",
        "    while True:\n",
        "        epoch += 1\n",
        "        for batch in range(int(data.shape[-1] / m)):\n",
        "            yield data[...,batch * m:(batch + 1) * m], epoch"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsEHzfzVJlgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(ai.Module):\n",
        "    def __init__(self):\n",
        "        self.g_fc = ai.Linear(z_dim, 8*gf_dim * 2 * 2)\n",
        "        self.g_bn1 = ai.BatchNorm((8*gf_dim, 2, 2))\n",
        "        self.g_deconv1 = ai.ConvTranspose2d(8*gf_dim, 4*gf_dim, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        self.g_bn2 = ai.BatchNorm((4*gf_dim, 4, 4))\n",
        "        self.g_deconv2 = ai.ConvTranspose2d(4*gf_dim, 2*gf_dim, kernel_size=5, stride=2, padding=2, a=0)\n",
        "        self.g_bn3 = ai.BatchNorm((2*gf_dim, 7, 7))\n",
        "        self.g_deconv3 = ai.ConvTranspose2d(2*gf_dim, gf_dim, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        self.g_bn4 = ai.BatchNorm((gf_dim, 14, 14))\n",
        "        self.g_deconv4 = ai.ConvTranspose2d(gf_dim, 1, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        \n",
        "    def forward(self, z):\n",
        "        o1 = ai.G.reshape(self.g_fc(z), (8*gf_dim, 2, 2))\n",
        "        o2 = ai.G.relu(self.g_bn1(o1))\n",
        "        o3 = ai.G.relu(self.g_bn2(self.g_deconv1(o2)))\n",
        "        o4 = ai.G.relu(self.g_bn3(self.g_deconv2(o3)))\n",
        "        o5 = ai.G.relu(self.g_bn4(self.g_deconv3(o4)))\n",
        "        fake_image = ai.G.tanh(self.g_deconv4(o5))\n",
        "        return fake_image"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nG_7CSfJlgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(ai.Module):\n",
        "    def __init__(self):\n",
        "        self.d_conv1 = ai.Conv2d(1, 64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_conv2 = ai.Conv2d(64, 2*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn1 = ai.BatchNorm((2*64, 7, 7))\n",
        "        self.d_conv3 = ai.Conv2d(2*64, 3*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn2 = ai.BatchNorm((3*64, 4, 4))\n",
        "        self.d_conv4 = ai.Conv2d(3*64, 4*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn3 = ai.BatchNorm((4*64, 2, 2))\n",
        "        self.d_fc = ai.Linear(1024, 1)\n",
        "        \n",
        "    def forward(self, image):\n",
        "        o1 = ai.G.lrelu(self.d_conv1(image))\n",
        "        o2 = ai.G.lrelu(self.d_bn1(self.d_conv2(o1)))\n",
        "        o3 = ai.G.lrelu(self.d_bn2(self.d_conv3(o2)))\n",
        "        o4 = ai.G.lrelu(self.d_bn3(self.d_conv4(o3)))\n",
        "        o5 = self.d_fc(o4)\n",
        "        return ai.G.sigmoid(o5)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l88SAS6rJlgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ef69f7ae-0c33-43a0-e15f-00b81277e79a"
      },
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "# generator.load('/content/drive/My Drive/GAN/Generator.npy')\n",
        "# discriminator.load('/content/drive/My Drive/GAN/Discriminator.npy')\n",
        "print(generator)\n",
        "print(discriminator)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  g_fc: Linear(input_features=100, output_features=2048, bias=True)\n",
            "  g_bn1: BatchNorm((512, 2, 2), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv1: ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            "  g_bn2: BatchNorm((256, 4, 4), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv2: ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(0, 0), bias=True)\n",
            "  g_bn3: BatchNorm((128, 7, 7), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv3: ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            "  g_bn4: BatchNorm((64, 14, 14), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv4: ConvTranspose2d(64, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            ")\n",
            "Discriminator(\n",
            "  d_conv1: Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_conv2: Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn1: BatchNorm((128, 7, 7), axis=-1, momentum=0.9, bias=True)\n",
            "  d_conv3: Conv2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn2: BatchNorm((192, 4, 4), axis=-1, momentum=0.9, bias=True)\n",
            "  d_conv4: Conv2d(192, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn3: BatchNorm((256, 2, 2), axis=-1, momentum=0.9, bias=True)\n",
            "  d_fc: Linear(input_features=1024, output_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md_IEa9CJlgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "L = ai.Loss(loss_fn='BCELoss')\n",
        "g_optim = ai.Optimizer(generator.parameters(), optim_fn='Adam', lr=lr, beta1=beta1)\n",
        "d_optim = ai.Optimizer(discriminator.parameters(), optim_fn='Adam', lr=lr, beta1=beta1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsfYfCeuJlg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it, epoch = 0, 0\n",
        "m = 64   # batch size\n",
        "n_discriminator = 1   # number of descriminator updates per generator update\n",
        "\n",
        "# real images data generator\n",
        "data = data_generator(m)\n",
        "\n",
        "sample_z = np.random.uniform(-1, 1, (z_dim, m))\n",
        "# sampled_images = np.load('/content/drive/My Drive/GAN/sampled_images.npy')\n",
        "sampled_images = None"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-6QzGr9Jlg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampler(sampled_images):\n",
        "    ai.G.grad_mode = False\n",
        "\n",
        "    # generate images like real data\n",
        "    fake_images = generator.forward(sample_z).data\n",
        "    fake_images = (fake_images + 1.) / 2.\n",
        "\n",
        "    if sampled_images is not None:\n",
        "        sampled_images = np.concatenate([sampled_images, fake_images], axis=-1)\n",
        "    else:\n",
        "        sampled_images = fake_images\n",
        "    \n",
        "    ai.G.grad_mode = True\n",
        "\n",
        "    return sampled_images"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUKbYB9EJlg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "df6fa618-8ffe-4cb1-9258-41b73b8cd453"
      },
      "source": [
        "for it in range(10000):\n",
        "    \n",
        "    # freeze generator before optimizing descriminator\n",
        "    for p in generator.parameters():\n",
        "        p.eval_grad = False\n",
        "\n",
        "    # training descriminator to identify real/fake data\n",
        "    for _ in range(n_discriminator):\n",
        "\n",
        "        real_images, epoch = data.__next__()\n",
        "        real_labels = np.ones((1, m))\n",
        "        if (real_images.shape[-1] != m):\n",
        "            continue\n",
        "\n",
        "        real_probs = discriminator.forward(real_images)\n",
        "        d_loss_real = L.loss(real_probs, real_labels)\n",
        "\n",
        "        z = np.random.randn(z_dim, m)\n",
        "        fake_images = generator.forward(z)\n",
        "        fake_labels =  np.zeros((1, m))\n",
        "\n",
        "        fake_probs = discriminator.forward(fake_images)\n",
        "        d_loss_fake = L.loss(fake_probs, fake_labels)\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.grad = np.zeros(d_loss.shape)\n",
        "\n",
        "        d_loss.backward()\n",
        "        d_optim.step()\n",
        "        d_optim.zero_grad()\n",
        "\n",
        "    # unfreeze generator\n",
        "    for p in generator.parameters():\n",
        "        p.eval_grad = True\n",
        "\n",
        "    # training generator to fool descriminator with fake data\n",
        "    z = np.random.uniform(-1, 1, (z_dim, m))\n",
        "    fake_images = generator.forward(z)\n",
        "    fake_labels =  np.ones((1, m))\n",
        "\n",
        "    fake_probs = discriminator.forward(fake_images)\n",
        "    g_loss = L.loss(fake_probs, fake_labels)\n",
        "\n",
        "    g_loss.backward()\n",
        "    g_optim.step()\n",
        "    g_optim.zero_grad()\n",
        "    d_optim.zero_grad()\n",
        "\n",
        "    if it%10 == 0:\n",
        "        print('Iter: {}, Epoch: {}, d_loss: {}, g_loss: {}'.format(it, epoch, d_loss.data[0, 0], g_loss.data[0, 0]))\n",
        "    \n",
        "    if it%100 == 0:\n",
        "        sampled_images=sampler(sampled_images)\n",
        "        np.save('/content/drive/My Drive/GAN/sampled_images.npy', sampled_images)\n",
        "        generator.save('/content/drive/My Drive/GAN/Generator.npy')\n",
        "        discriminator.save('/content/drive/My Drive/GAN/Discriminator.npy')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using Adam\n",
            "using Adam\n",
            "Iter: 0, Epoch: 1, d_loss: 1.4335286368865323, g_loss: 0.833239350290024\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 10, Epoch: 1, d_loss: 1.2385491067579015, g_loss: 0.8104526989292754\n",
            "Iter: 20, Epoch: 1, d_loss: 1.0340996498594213, g_loss: 0.9235075225132299\n",
            "Iter: 30, Epoch: 1, d_loss: 0.7504887007381555, g_loss: 1.2236338665452886\n",
            "Iter: 40, Epoch: 1, d_loss: 0.6435615975799105, g_loss: 1.380117115563181\n",
            "Iter: 50, Epoch: 1, d_loss: 0.7209061828820125, g_loss: 1.4645621703774203\n",
            "Iter: 60, Epoch: 1, d_loss: 0.4668926745634556, g_loss: 1.582988254356857\n",
            "Iter: 70, Epoch: 1, d_loss: 0.49439195351069876, g_loss: 1.6848709696560589\n",
            "Iter: 80, Epoch: 1, d_loss: 0.4686239724260851, g_loss: 1.7883883879502942\n",
            "Iter: 90, Epoch: 1, d_loss: 0.4997568281571594, g_loss: 1.55228654791657\n",
            "Iter: 100, Epoch: 1, d_loss: 0.45042082957443313, g_loss: 1.8131939222699864\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 110, Epoch: 1, d_loss: 0.3055905160552942, g_loss: 2.026397768869517\n",
            "Iter: 120, Epoch: 1, d_loss: 0.49717736235737864, g_loss: 1.7418906412356292\n",
            "Iter: 130, Epoch: 1, d_loss: 0.3258739202901878, g_loss: 2.028593318950569\n",
            "Iter: 140, Epoch: 1, d_loss: 0.5456728430692944, g_loss: 1.992663380767786\n",
            "Iter: 150, Epoch: 1, d_loss: 0.311561231286141, g_loss: 2.1455086623451427\n",
            "Iter: 160, Epoch: 1, d_loss: 0.23711551238441084, g_loss: 2.366879849207429\n",
            "Iter: 170, Epoch: 1, d_loss: 0.2073565177284789, g_loss: 2.3974372952965273\n",
            "Iter: 180, Epoch: 1, d_loss: 0.2287560506083247, g_loss: 2.3995064579864596\n",
            "Iter: 190, Epoch: 1, d_loss: 0.31882434864796516, g_loss: 2.0862657701507543\n",
            "Iter: 200, Epoch: 1, d_loss: 0.28113118087889666, g_loss: 2.283240520682989\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 210, Epoch: 1, d_loss: 0.26129635555626424, g_loss: 2.468552333726585\n",
            "Iter: 220, Epoch: 1, d_loss: 0.35942852722503293, g_loss: 2.107465662613845\n",
            "Iter: 230, Epoch: 1, d_loss: 0.4182456212514276, g_loss: 1.9561870823245313\n",
            "Iter: 240, Epoch: 1, d_loss: 0.2501546174339776, g_loss: 2.37687686640781\n",
            "Iter: 250, Epoch: 1, d_loss: 0.1614543972541063, g_loss: 2.577913468818462\n",
            "Iter: 260, Epoch: 1, d_loss: 0.17453473615688658, g_loss: 2.772712536300515\n",
            "Iter: 270, Epoch: 1, d_loss: 0.16006382472676983, g_loss: 2.735224719722455\n",
            "Iter: 280, Epoch: 1, d_loss: 0.14840069931262373, g_loss: 2.821590119262473\n",
            "Iter: 290, Epoch: 1, d_loss: 0.12587174082751024, g_loss: 2.925780408375839\n",
            "Iter: 300, Epoch: 1, d_loss: 0.16835282325822193, g_loss: 3.0269887317314446\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 310, Epoch: 1, d_loss: 0.29743041796432457, g_loss: 2.3529327463031655\n",
            "Iter: 320, Epoch: 1, d_loss: 0.20033807457103367, g_loss: 2.397639809874478\n",
            "Iter: 330, Epoch: 1, d_loss: 0.1636136627048615, g_loss: 2.7213829105135727\n",
            "Iter: 340, Epoch: 1, d_loss: 0.235007763773899, g_loss: 2.7839992510717884\n",
            "Iter: 350, Epoch: 1, d_loss: 0.20950187466194528, g_loss: 2.8216777109150173\n",
            "Iter: 360, Epoch: 1, d_loss: 0.10546074427604449, g_loss: 2.909577217683975\n",
            "Iter: 370, Epoch: 1, d_loss: 0.21484504110975633, g_loss: 2.6670634163710965\n",
            "Iter: 380, Epoch: 1, d_loss: 0.10620334618467447, g_loss: 2.891093681173012\n",
            "Iter: 390, Epoch: 1, d_loss: 0.13312213112838656, g_loss: 2.7911852668746935\n",
            "Iter: 400, Epoch: 1, d_loss: 0.17978072646443488, g_loss: 2.9478371272848136\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 410, Epoch: 1, d_loss: 0.12740988838567452, g_loss: 3.1116998717247166\n",
            "Iter: 420, Epoch: 1, d_loss: 0.0953843784768626, g_loss: 3.106011496702794\n",
            "Iter: 430, Epoch: 1, d_loss: 0.14014766719056584, g_loss: 2.8961426328134974\n",
            "Iter: 440, Epoch: 1, d_loss: 0.08806694606316155, g_loss: 3.0160636479931107\n",
            "Iter: 450, Epoch: 1, d_loss: 0.07588904332501775, g_loss: 3.1439518687682537\n",
            "Iter: 460, Epoch: 1, d_loss: 0.10540200168075553, g_loss: 2.925029537383075\n",
            "Iter: 470, Epoch: 1, d_loss: 0.2277154176672801, g_loss: 2.909146891566872\n",
            "Iter: 480, Epoch: 1, d_loss: 0.09776326900311975, g_loss: 2.840518535834668\n",
            "Iter: 490, Epoch: 1, d_loss: 0.13418827836985453, g_loss: 2.97821710918777\n",
            "Iter: 500, Epoch: 1, d_loss: 0.07985055744805286, g_loss: 3.159942461290758\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 510, Epoch: 1, d_loss: 0.07746755114973979, g_loss: 3.393230245009091\n",
            "Iter: 520, Epoch: 1, d_loss: 0.07677503243784756, g_loss: 3.4971540467712403\n",
            "Iter: 530, Epoch: 1, d_loss: 0.07469489128596177, g_loss: 3.5967344421570484\n",
            "Iter: 540, Epoch: 1, d_loss: 0.05888365820071775, g_loss: 3.5896394740603967\n",
            "Iter: 550, Epoch: 1, d_loss: 0.12799868695595013, g_loss: 3.4961136762163747\n",
            "Iter: 560, Epoch: 1, d_loss: 0.3843022192827019, g_loss: 3.440109288858281\n",
            "Iter: 570, Epoch: 1, d_loss: 0.05424630743193081, g_loss: 3.5316446870388765\n",
            "Iter: 580, Epoch: 1, d_loss: 0.23415126633603983, g_loss: 3.659648863387714\n",
            "Iter: 590, Epoch: 1, d_loss: 0.16721270579768144, g_loss: 3.36034581183824\n",
            "Iter: 600, Epoch: 1, d_loss: 0.058327283218062374, g_loss: 3.5409446708009664\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 610, Epoch: 1, d_loss: 0.04363471458215397, g_loss: 3.614100479578341\n",
            "Iter: 620, Epoch: 1, d_loss: 0.12193324501587696, g_loss: 3.2870110806770425\n",
            "Iter: 630, Epoch: 1, d_loss: 0.05605896863359856, g_loss: 3.416870749124481\n",
            "Iter: 640, Epoch: 1, d_loss: 0.06674029830378325, g_loss: 3.6108832162047055\n",
            "Iter: 650, Epoch: 1, d_loss: 0.14741897822215777, g_loss: 3.475526338548044\n",
            "Iter: 660, Epoch: 1, d_loss: 0.05022450512716764, g_loss: 3.565036493977557\n",
            "Iter: 670, Epoch: 1, d_loss: 0.08695104163389672, g_loss: 3.61776273440084\n",
            "Iter: 680, Epoch: 1, d_loss: 0.051321359568489475, g_loss: 3.7331298288139716\n",
            "Iter: 690, Epoch: 1, d_loss: 0.057612883360555735, g_loss: 3.8292373129085684\n",
            "Iter: 700, Epoch: 1, d_loss: 0.036227070127583784, g_loss: 3.8866540453464617\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 710, Epoch: 1, d_loss: 0.07111392063234058, g_loss: 3.917115268507432\n",
            "Iter: 720, Epoch: 1, d_loss: 0.44351020848712647, g_loss: 3.778412730731568\n",
            "Iter: 730, Epoch: 1, d_loss: 0.045640767675787966, g_loss: 3.7131613392839595\n",
            "Iter: 740, Epoch: 1, d_loss: 0.07169566708302397, g_loss: 3.7688519995260377\n",
            "Iter: 750, Epoch: 1, d_loss: 0.05463751465087924, g_loss: 3.8082586123371978\n",
            "Iter: 760, Epoch: 1, d_loss: 0.04130291824586073, g_loss: 3.8522951469228164\n",
            "Iter: 770, Epoch: 1, d_loss: 0.06934065856458399, g_loss: 3.937932931725798\n",
            "Iter: 780, Epoch: 1, d_loss: 0.04498108187633741, g_loss: 4.035097100802955\n",
            "Iter: 790, Epoch: 1, d_loss: 0.07369054390194678, g_loss: 4.179398693758266\n",
            "Iter: 800, Epoch: 1, d_loss: 0.02945468104552989, g_loss: 4.267617165260122\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 810, Epoch: 1, d_loss: 0.032027206510545206, g_loss: 4.251807413710749\n",
            "Iter: 820, Epoch: 1, d_loss: 0.02512637537131028, g_loss: 4.389010290068061\n",
            "Iter: 830, Epoch: 1, d_loss: 0.08290653797879952, g_loss: 4.0620048862486\n",
            "Iter: 840, Epoch: 1, d_loss: 0.04966553547191327, g_loss: 4.024606521324351\n",
            "Iter: 850, Epoch: 1, d_loss: 0.058248581859456916, g_loss: 4.020102746796903\n",
            "Iter: 860, Epoch: 1, d_loss: 0.05410213247435977, g_loss: 3.914379338280154\n",
            "Iter: 870, Epoch: 1, d_loss: 0.04911103868931428, g_loss: 4.138094491739666\n",
            "Iter: 880, Epoch: 1, d_loss: 0.04069916660324234, g_loss: 4.2049637293167725\n",
            "Iter: 890, Epoch: 1, d_loss: 0.27112573714198385, g_loss: 4.0586018394813035\n",
            "Iter: 900, Epoch: 1, d_loss: 0.0956550731615595, g_loss: 3.9138658145418344\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 910, Epoch: 1, d_loss: 0.04320180416059553, g_loss: 3.8012631710064193\n",
            "Iter: 920, Epoch: 1, d_loss: 0.08853039753025035, g_loss: 3.940357961215574\n",
            "Iter: 930, Epoch: 1, d_loss: 0.10841686781488813, g_loss: 3.496902122938711\n",
            "Iter: 940, Epoch: 1, d_loss: 0.051578014393621224, g_loss: 3.8838075248263326\n",
            "Iter: 950, Epoch: 1, d_loss: 0.06855124842508178, g_loss: 3.888459806321369\n",
            "Iter: 960, Epoch: 1, d_loss: 0.04093155369607841, g_loss: 4.129685255781319\n",
            "Iter: 970, Epoch: 1, d_loss: 0.030414414722096557, g_loss: 4.2657187291618355\n",
            "Iter: 980, Epoch: 1, d_loss: 0.05613654393699421, g_loss: 4.213712317115249\n",
            "Iter: 990, Epoch: 1, d_loss: 0.024101956324547126, g_loss: 4.245838534478538\n",
            "Iter: 1000, Epoch: 1, d_loss: 0.03543331909057067, g_loss: 4.256345503494756\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 1010, Epoch: 1, d_loss: 0.037640756856807414, g_loss: 4.227409887301948\n",
            "Iter: 1020, Epoch: 1, d_loss: 0.07118263180058701, g_loss: 4.290133227792463\n",
            "Iter: 1030, Epoch: 1, d_loss: 0.06587720195066245, g_loss: 4.2469204125486035\n",
            "Iter: 1040, Epoch: 1, d_loss: 0.04413635713855741, g_loss: 4.569961678588456\n",
            "Iter: 1050, Epoch: 1, d_loss: 0.06448961229248565, g_loss: 4.36695814121948\n",
            "Iter: 1060, Epoch: 1, d_loss: 0.5156481723244224, g_loss: 3.9048132814385834\n",
            "Iter: 1070, Epoch: 1, d_loss: 0.06390721792591296, g_loss: 3.976660850128753\n",
            "Iter: 1080, Epoch: 1, d_loss: 0.17756250112064337, g_loss: 3.606660487120412\n",
            "Iter: 1090, Epoch: 1, d_loss: 0.04674020322266357, g_loss: 3.822720297754127\n",
            "Iter: 1100, Epoch: 2, d_loss: 0.03772449540428911, g_loss: 4.066011560990876\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 1110, Epoch: 2, d_loss: 0.03239709677297279, g_loss: 4.178792820378296\n",
            "Iter: 1120, Epoch: 2, d_loss: 0.03644064198654299, g_loss: 4.325977925799306\n",
            "Iter: 1130, Epoch: 2, d_loss: 0.046883872394179446, g_loss: 4.064488037846019\n",
            "Iter: 1140, Epoch: 2, d_loss: 0.035936777762755466, g_loss: 4.557217620527779\n",
            "Iter: 1150, Epoch: 2, d_loss: 0.026661193271474405, g_loss: 4.487234132656786\n",
            "Iter: 1160, Epoch: 2, d_loss: 0.03157719547988745, g_loss: 4.455683917139899\n",
            "Iter: 1170, Epoch: 2, d_loss: 0.024592578858388295, g_loss: 4.45103508664444\n",
            "Iter: 1180, Epoch: 2, d_loss: 0.07559898364999697, g_loss: 4.573941922625146\n",
            "Iter: 1190, Epoch: 2, d_loss: 0.14884671925036724, g_loss: 4.769831382973915\n",
            "Iter: 1200, Epoch: 2, d_loss: 0.03505925401711419, g_loss: 4.641586947474284\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 1210, Epoch: 2, d_loss: 0.08092742145827467, g_loss: 4.517249043346142\n",
            "Iter: 1220, Epoch: 2, d_loss: 0.019031362931683376, g_loss: 4.8827322477494866\n",
            "Iter: 1230, Epoch: 2, d_loss: 0.022774178356483717, g_loss: 4.607118023989971\n",
            "Iter: 1240, Epoch: 2, d_loss: 0.031190456461014315, g_loss: 4.89663360566602\n",
            "Iter: 1250, Epoch: 2, d_loss: 0.018622134845399763, g_loss: 4.805092422099042\n",
            "Iter: 1260, Epoch: 2, d_loss: 0.024716995964880455, g_loss: 4.861160929266683\n",
            "Iter: 1270, Epoch: 2, d_loss: 0.044350810031640785, g_loss: 4.781780680788627\n",
            "Iter: 1280, Epoch: 2, d_loss: 0.16517442871441337, g_loss: 5.03064444101644\n",
            "Iter: 1290, Epoch: 2, d_loss: 0.032686177354491905, g_loss: 5.2012829693480365\n",
            "Iter: 1300, Epoch: 2, d_loss: 0.03625632197537357, g_loss: 5.158696356959567\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 1310, Epoch: 2, d_loss: 0.03375149250693788, g_loss: 4.57242442550299\n",
            "Iter: 1320, Epoch: 2, d_loss: 0.015892678738780724, g_loss: 4.7412197712962865\n",
            "Iter: 1330, Epoch: 2, d_loss: 0.06567922753081343, g_loss: 4.465686269489828\n",
            "Iter: 1340, Epoch: 2, d_loss: 0.018838068319731026, g_loss: 4.556685699936526\n",
            "Iter: 1350, Epoch: 2, d_loss: 0.012435227560889217, g_loss: 4.446162443658603\n",
            "Iter: 1360, Epoch: 2, d_loss: 0.028851890307891224, g_loss: 4.937521439611716\n",
            "Iter: 1370, Epoch: 2, d_loss: 0.01862972195986737, g_loss: 4.364621276317957\n",
            "Iter: 1380, Epoch: 2, d_loss: 0.012369767674422619, g_loss: 4.74594718097858\n",
            "Iter: 1390, Epoch: 2, d_loss: 0.016873993080562668, g_loss: 4.827603263537727\n",
            "Iter: 1400, Epoch: 2, d_loss: 0.09145153021339344, g_loss: 4.25652644866372\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 1410, Epoch: 2, d_loss: 0.03639232821984719, g_loss: 3.87097562679613\n",
            "Iter: 1420, Epoch: 2, d_loss: 0.021470645844794838, g_loss: 4.259494566503381\n",
            "Iter: 1430, Epoch: 2, d_loss: 0.02730330636788341, g_loss: 4.51510638532237\n",
            "Iter: 1440, Epoch: 2, d_loss: 0.01737848111224257, g_loss: 4.726611736453859\n",
            "Iter: 1450, Epoch: 2, d_loss: 0.015914037585853493, g_loss: 4.411432212439018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f809c0846e37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mg_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mg_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/parameter.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, to)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_node_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backprop_op'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# executing the back-propagation operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/graph.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;31m# return (K.grad, x.grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'func'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'conv_transpose2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'backprop_op'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/graph.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m()\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                     \u001b[0mx_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_grad_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;31m# Reshape the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}