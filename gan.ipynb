{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirambandi/GAN/blob/master/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RTzsFdfJn69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# when running in colab notebooks, first install library\n",
        "!pip install import-ai\n",
        "# upload respective dataset manually from examples directory of the library or download as below\n",
        "!apt install subversion\n",
        "!svn checkout https://github.com/srirambandi/ai/trunk/examples/MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY0FMFMLJlgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ai\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNYfGAkfJlgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_dim = 100\n",
        "gf_dim = 64\n",
        "df_dim = 64"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiFy00xkJ3X1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ai.manual_seed(2357)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ3zS_s-Jlgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(m):\n",
        "    train_dict = np.load('MNIST/train.npy', allow_pickle=True)\n",
        "    test_dict = np.load('MNIST/test.npy', allow_pickle=True)\n",
        "    data = np.concatenate([train_dict.item()['data'], test_dict.item()['data']])\n",
        "    data = data.transpose(1, 2, 0)   # making data batch-last\n",
        "    data = data.reshape(1, *data.shape) / 255   # adding channel dimension and normalizing data\n",
        "    epoch = 0\n",
        "    \n",
        "    while True:\n",
        "        epoch += 1\n",
        "        for batch in range(int(data.shape[-1] / m)):\n",
        "            yield data[...,batch * m:(batch + 1) * m], epoch"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsEHzfzVJlgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(ai.Module):\n",
        "    def __init__(self):\n",
        "        self.g_fc = ai.Linear(z_dim, 8*gf_dim * 2 * 2)\n",
        "        self.g_bn1 = ai.BatchNorm((8*gf_dim, 2, 2))\n",
        "        self.g_deconv1 = ai.ConvTranspose2d(8*gf_dim, 4*gf_dim, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        self.g_bn2 = ai.BatchNorm((4*gf_dim, 4, 4))\n",
        "        self.g_deconv2 = ai.ConvTranspose2d(4*gf_dim, 2*gf_dim, kernel_size=5, stride=2, padding=2, a=0)\n",
        "        self.g_bn3 = ai.BatchNorm((2*gf_dim, 7, 7))\n",
        "        self.g_deconv3 = ai.ConvTranspose2d(2*gf_dim, gf_dim, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        self.g_bn4 = ai.BatchNorm((gf_dim, 14, 14))\n",
        "        self.g_deconv4 = ai.ConvTranspose2d(gf_dim, 1, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        \n",
        "    def forward(self, z):\n",
        "        o1 = ai.G.reshape(self.g_fc(z), (8*gf_dim, 2, 2))\n",
        "        o2 = ai.G.relu(self.g_bn1(o1))\n",
        "        o3 = ai.G.relu(self.g_bn2(self.g_deconv1(o2)))\n",
        "        o4 = ai.G.relu(self.g_bn3(self.g_deconv2(o3)))\n",
        "        o5 = ai.G.relu(self.g_bn4(self.g_deconv3(o4)))\n",
        "        fake_image = ai.G.tanh(self.g_deconv4(o5))\n",
        "        return fake_image"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nG_7CSfJlgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(ai.Module):\n",
        "    def __init__(self):\n",
        "        self.d_conv1 = ai.Conv2d(1, 64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_conv2 = ai.Conv2d(64, 2*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn1 = ai.BatchNorm((2*64, 7, 7))\n",
        "        self.d_conv3 = ai.Conv2d(2*64, 3*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn2 = ai.BatchNorm((3*64, 4, 4))\n",
        "        self.d_conv4 = ai.Conv2d(3*64, 4*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn3 = ai.BatchNorm((4*64, 2, 2))\n",
        "        self.d_fc = ai.Linear(1024, 1)\n",
        "        \n",
        "    def forward(self, image):\n",
        "        o1 = ai.G.lrelu(self.d_conv1(image))\n",
        "        o2 = ai.G.lrelu(self.d_bn1(self.d_conv2(o1)))\n",
        "        o3 = ai.G.lrelu(self.d_bn2(self.d_conv3(o2)))\n",
        "        o4 = ai.G.lrelu(self.d_bn3(self.d_conv4(o3)))\n",
        "        o5 = self.d_fc(o4)\n",
        "        return ai.G.sigmoid(o5)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l88SAS6rJlgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "936f0834-c9c6-439d-f485-37fa4089e929"
      },
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "print(generator)\n",
        "print(discriminator)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  g_fc: Linear(input_features=100, output_features=2048, bias=True)\n",
            "  g_bn1: BatchNorm((512, 2, 2), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv1: ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            "  g_bn2: BatchNorm((256, 4, 4), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv2: ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(0, 0), bias=True)\n",
            "  g_bn3: BatchNorm((128, 7, 7), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv3: ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            "  g_bn4: BatchNorm((64, 14, 14), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv4: ConvTranspose2d(64, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            ")\n",
            "Discriminator(\n",
            "  d_conv1: Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_conv2: Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn1: BatchNorm((128, 7, 7), axis=-1, momentum=0.9, bias=True)\n",
            "  d_conv3: Conv2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn2: BatchNorm((192, 4, 4), axis=-1, momentum=0.9, bias=True)\n",
            "  d_conv4: Conv2d(192, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn3: BatchNorm((256, 2, 2), axis=-1, momentum=0.9, bias=True)\n",
            "  d_fc: Linear(input_features=1024, output_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md_IEa9CJlgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "L = ai.Loss(loss_fn='BCELoss')\n",
        "g_optim = ai.Optimizer(generator.parameters(), optim_fn='Adam', lr=lr, beta1=beta1)\n",
        "d_optim = ai.Optimizer(discriminator.parameters(), optim_fn='Adam', lr=lr, beta1=beta1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsfYfCeuJlg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it, epoch = 0, 0\n",
        "m = 64   # batch size\n",
        "n_discriminator = 1   # number of descriminator updates per generator update\n",
        "\n",
        "# real images data generator\n",
        "data = data_generator(m)\n",
        "\n",
        "sample_z = np.random.randn(z_dim, m)\n",
        "sample_images = None"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-6QzGr9Jlg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampler(sample_images):\n",
        "    ai.G.grad_mode = False\n",
        "\n",
        "    # generate images like real data\n",
        "    fake_images = generator.forward(sample_z).data\n",
        "    fake_images = (fake_images + 1.) / 2.\n",
        "\n",
        "    if sample_images is not None:\n",
        "        sample_images = np.concatenate([sample_images, fake_images], axis=-1)\n",
        "    else:\n",
        "        sample_images = fake_images\n",
        "\n",
        "    np.save('sample_images.npy', sample_images)\n",
        "    \n",
        "    ai.G.grad_mode = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUKbYB9EJlg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c4e6e84b-15c3-490e-c593-0d9aa0134dfa"
      },
      "source": [
        "for it in range(10000):\n",
        "    \n",
        "    # freeze generator before optimizing descriminator\n",
        "    for p in generator.parameters():\n",
        "        p.eval_grad = False\n",
        "\n",
        "    # training descriminator to identify real/fake data\n",
        "    for _ in range(n_discriminator):\n",
        "\n",
        "        real_images, epoch = data.__next__()\n",
        "        real_labels = np.ones((1, m))\n",
        "        if (real_images.shape[-1] != m):\n",
        "            continue\n",
        "\n",
        "        real_probs = discriminator.forward(real_images)\n",
        "        d_loss_real = L.loss(real_probs, real_labels)\n",
        "\n",
        "        z = np.random.randn(z_dim, m)\n",
        "        fake_images = generator.forward(z)\n",
        "        fake_labels =  np.zeros((1, m))\n",
        "\n",
        "        fake_probs = discriminator.forward(fake_images)\n",
        "        d_loss_fake = L.loss(fake_probs, fake_labels)\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.grad = np.zeros(d_loss.shape)\n",
        "\n",
        "        d_loss.backward()\n",
        "        d_optim.step()\n",
        "        d_optim.zero_grad()\n",
        "\n",
        "    # unfreeze generator\n",
        "    for p in generator.parameters():\n",
        "        p.eval_grad = True\n",
        "\n",
        "    # training generator to fool descriminator with fake data\n",
        "    z = np.random.randn(z_dim, m)\n",
        "    fake_images = generator.forward(z)\n",
        "    fake_labels =  np.ones((1, m))\n",
        "\n",
        "    fake_probs = discriminator.forward(fake_images)\n",
        "    g_loss = L.loss(fake_probs, fake_labels)\n",
        "\n",
        "    g_loss.backward()\n",
        "    g_optim.step()\n",
        "    g_optim.zero_grad()\n",
        "    d_optim.zero_grad()\n",
        "\n",
        "    if it%10 == 0:\n",
        "        print('Iter: {}, Epoch: {}, d_loss: {}, g_loss: {}'.format(it, epoch, d_loss.data[0, 0], g_loss.data[0, 0]))\n",
        "    \n",
        "    if it%100 == 0:\n",
        "        sampler(sample_images)\n",
        "        generator.save()\n",
        "        discriminator.save()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using Adam\n",
            "using Adam\n",
            "Iter: 0, Epoch: 1, d_loss: 1.4048446477600869, g_loss: 0.6804074710917262\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Discriminator.npy\n",
            "Iter: 10, Epoch: 1, d_loss: 1.3479563831413852, g_loss: 0.7364326437366828\n",
            "Iter: 20, Epoch: 1, d_loss: 1.2466618940128118, g_loss: 0.7823281578918218\n",
            "Iter: 30, Epoch: 1, d_loss: 1.1397869121140072, g_loss: 0.8969086439411424\n",
            "Iter: 40, Epoch: 1, d_loss: 1.018276474696106, g_loss: 0.9880030129121773\n",
            "Iter: 50, Epoch: 1, d_loss: 1.059570664449264, g_loss: 1.0494747893989744\n",
            "Iter: 60, Epoch: 1, d_loss: 0.8187982379145465, g_loss: 1.1898379829550205\n",
            "Iter: 70, Epoch: 1, d_loss: 0.8689026057899547, g_loss: 1.1944627486030963\n",
            "Iter: 80, Epoch: 1, d_loss: 0.776076467518586, g_loss: 1.2416419256731888\n",
            "Iter: 90, Epoch: 1, d_loss: 0.5566131166461864, g_loss: 1.4670736797058295\n",
            "Iter: 100, Epoch: 1, d_loss: 0.600054149024182, g_loss: 1.4980203464252753\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Discriminator.npy\n",
            "Iter: 110, Epoch: 1, d_loss: 0.5095038507905147, g_loss: 1.584069340829894\n",
            "Iter: 120, Epoch: 1, d_loss: 0.6260397206083665, g_loss: 1.6139280937479992\n",
            "Iter: 130, Epoch: 1, d_loss: 0.46786730419227485, g_loss: 1.7072427928247311\n",
            "Iter: 140, Epoch: 1, d_loss: 0.4669130398146925, g_loss: 1.8380628216005352\n",
            "Iter: 150, Epoch: 1, d_loss: 0.3453449269182917, g_loss: 1.842739487918707\n",
            "Iter: 160, Epoch: 1, d_loss: 0.5031995828706588, g_loss: 2.032324852442396\n",
            "Iter: 170, Epoch: 1, d_loss: 0.39836913172607824, g_loss: 2.068369227753786\n",
            "Iter: 180, Epoch: 1, d_loss: 0.3002980776456875, g_loss: 2.2405646713755334\n",
            "Iter: 190, Epoch: 1, d_loss: 0.3563701933064361, g_loss: 2.2610160509890447\n",
            "Iter: 200, Epoch: 1, d_loss: 0.24145452780204368, g_loss: 2.3404529921731596\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Discriminator.npy\n",
            "Iter: 210, Epoch: 1, d_loss: 0.5250817866462083, g_loss: 1.9765980271724026\n",
            "Iter: 220, Epoch: 1, d_loss: 0.2913713668597362, g_loss: 2.216422840880014\n",
            "Iter: 230, Epoch: 1, d_loss: 0.4686970911473035, g_loss: 2.205481850790993\n",
            "Iter: 240, Epoch: 1, d_loss: 0.43852278694775, g_loss: 1.9884658897091143\n",
            "Iter: 250, Epoch: 1, d_loss: 0.37098623737256353, g_loss: 2.2680093049638645\n",
            "Iter: 260, Epoch: 1, d_loss: 0.18400796119580287, g_loss: 2.419208320729705\n",
            "Iter: 270, Epoch: 1, d_loss: 0.24397599449590018, g_loss: 2.419495730286858\n",
            "Iter: 280, Epoch: 1, d_loss: 0.2986278974943063, g_loss: 2.620447120360608\n",
            "Iter: 290, Epoch: 1, d_loss: 0.204170434157303, g_loss: 2.647787181054791\n",
            "Iter: 300, Epoch: 1, d_loss: 0.24303538779722694, g_loss: 2.6554249162968615\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Discriminator.npy\n",
            "Iter: 310, Epoch: 1, d_loss: 0.16717662004989575, g_loss: 2.9735663815084017\n",
            "Iter: 320, Epoch: 1, d_loss: 0.18219033777866772, g_loss: 2.779999570043873\n",
            "Iter: 330, Epoch: 1, d_loss: 0.28808945628069055, g_loss: 2.5806878769939137\n",
            "Iter: 340, Epoch: 1, d_loss: 0.26957571120204016, g_loss: 2.7037061264146143\n",
            "Iter: 350, Epoch: 1, d_loss: 0.32627882363965177, g_loss: 2.643382717010726\n",
            "Iter: 360, Epoch: 1, d_loss: 0.1507821082990957, g_loss: 3.1263308509382988\n",
            "Iter: 370, Epoch: 1, d_loss: 0.21683657451158844, g_loss: 2.8553570237880406\n",
            "Iter: 380, Epoch: 1, d_loss: 0.08734830947664164, g_loss: 3.2097474708170175\n",
            "Iter: 390, Epoch: 1, d_loss: 0.1709606079211889, g_loss: 3.1422899822598978\n",
            "Iter: 400, Epoch: 1, d_loss: 0.11562542620254543, g_loss: 2.959863092433074\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Discriminator.npy\n",
            "Iter: 410, Epoch: 1, d_loss: 0.06911188511505595, g_loss: 3.54089861663374\n",
            "Iter: 420, Epoch: 1, d_loss: 0.0723433622053537, g_loss: 3.2730518547283847\n",
            "Iter: 430, Epoch: 1, d_loss: 0.0725807412743655, g_loss: 3.345380491534627\n",
            "Iter: 440, Epoch: 1, d_loss: 0.15109665199248407, g_loss: 3.3238966496369526\n",
            "Iter: 450, Epoch: 1, d_loss: 0.06783233324395041, g_loss: 3.2934213285603624\n",
            "Iter: 460, Epoch: 1, d_loss: 0.10269229553423748, g_loss: 3.3108026533913986\n",
            "Iter: 470, Epoch: 1, d_loss: 0.2272359881967734, g_loss: 3.600815611875237\n",
            "Iter: 480, Epoch: 1, d_loss: 0.12799057430722408, g_loss: 3.4115922017200497\n",
            "Iter: 490, Epoch: 1, d_loss: 0.3297644131149007, g_loss: 3.3159044341609856\n",
            "Iter: 500, Epoch: 1, d_loss: 0.07935220606276155, g_loss: 3.303633315833662\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Discriminator.npy\n",
            "Iter: 510, Epoch: 1, d_loss: 0.09785315720462409, g_loss: 3.329912029644226\n",
            "Iter: 520, Epoch: 1, d_loss: 0.08920606903217007, g_loss: 3.5527727568929945\n",
            "Iter: 530, Epoch: 1, d_loss: 0.04765427614560595, g_loss: 3.4844427488564356\n",
            "Iter: 540, Epoch: 1, d_loss: 0.07240151441081864, g_loss: 3.552020737206691\n",
            "Iter: 550, Epoch: 1, d_loss: 0.0744883406765866, g_loss: 3.5316081822676146\n",
            "Iter: 560, Epoch: 1, d_loss: 0.08518757004663818, g_loss: 3.7242756876820993\n",
            "Iter: 570, Epoch: 1, d_loss: 0.040207532337225696, g_loss: 4.150091430046387\n",
            "Iter: 580, Epoch: 1, d_loss: 0.04436288908916893, g_loss: 4.0685275280000175\n",
            "Iter: 590, Epoch: 1, d_loss: 0.1412714850212911, g_loss: 3.639405865717574\n",
            "Iter: 600, Epoch: 1, d_loss: 0.04711046696382215, g_loss: 4.103914275199591\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Discriminator.npy\n",
            "Iter: 610, Epoch: 1, d_loss: 0.04614672792522273, g_loss: 3.8840341849109317\n",
            "Iter: 620, Epoch: 1, d_loss: 0.05822463620313957, g_loss: 4.009673429856786\n",
            "Iter: 630, Epoch: 1, d_loss: 0.08246353344373825, g_loss: 4.132329026050825\n",
            "Iter: 640, Epoch: 1, d_loss: 0.04670098331571178, g_loss: 3.6600513247046536\n",
            "Iter: 650, Epoch: 1, d_loss: 0.039898729699740204, g_loss: 3.725552476877564\n",
            "Iter: 660, Epoch: 1, d_loss: 0.038303560129863294, g_loss: 4.117668966408765\n",
            "Iter: 670, Epoch: 1, d_loss: 0.04229855375249686, g_loss: 3.812747759429819\n",
            "Iter: 680, Epoch: 1, d_loss: 0.09399611569459616, g_loss: 4.083052760230256\n",
            "Iter: 690, Epoch: 1, d_loss: 0.07005894178264375, g_loss: 3.7609907089249344\n",
            "Iter: 700, Epoch: 1, d_loss: 0.045139421015489, g_loss: 3.6207481936496855\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Discriminator.npy\n",
            "Iter: 710, Epoch: 1, d_loss: 0.04187324262677117, g_loss: 3.595699988357852\n",
            "Iter: 720, Epoch: 1, d_loss: 0.05250584928835089, g_loss: 4.08649370445933\n",
            "Iter: 730, Epoch: 1, d_loss: 0.0724916008767261, g_loss: 3.8285487834928205\n",
            "Iter: 740, Epoch: 1, d_loss: 0.030150786384392413, g_loss: 4.278678210513521\n",
            "Iter: 750, Epoch: 1, d_loss: 0.03076813778750667, g_loss: 4.1357716429504725\n",
            "Iter: 760, Epoch: 1, d_loss: 0.0464764594739066, g_loss: 4.2648138331059275\n",
            "Iter: 770, Epoch: 1, d_loss: 0.055626033942786514, g_loss: 4.700401099275483\n",
            "Iter: 780, Epoch: 1, d_loss: 0.026880575225644937, g_loss: 3.932546413947051\n",
            "Iter: 790, Epoch: 1, d_loss: 0.06356237850394347, g_loss: 3.460036865410876\n",
            "Iter: 800, Epoch: 1, d_loss: 0.0618512365531594, g_loss: 3.3809271065841333\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Discriminator.npy\n",
            "Iter: 810, Epoch: 1, d_loss: 0.05458290228517489, g_loss: 4.106499156438014\n",
            "Iter: 820, Epoch: 1, d_loss: 0.0315246292482023, g_loss: 4.132344790242435\n",
            "Iter: 830, Epoch: 1, d_loss: 0.029327215890609274, g_loss: 4.225536746840945\n",
            "Iter: 840, Epoch: 1, d_loss: 0.02920074613686264, g_loss: 3.8835851757569353\n",
            "Iter: 850, Epoch: 1, d_loss: 0.029121173747122406, g_loss: 4.50639517219242\n",
            "Iter: 860, Epoch: 1, d_loss: 0.027813576036459405, g_loss: 4.492162020660092\n",
            "Iter: 870, Epoch: 1, d_loss: 0.019386017061961195, g_loss: 4.30786534432783\n",
            "Iter: 880, Epoch: 1, d_loss: 0.02048650574642702, g_loss: 4.542602704956275\n",
            "Iter: 890, Epoch: 1, d_loss: 0.04949831134192366, g_loss: 4.021313958597423\n",
            "Iter: 900, Epoch: 1, d_loss: 0.0197313207737067, g_loss: 4.439297120393739\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Discriminator.npy\n",
            "Iter: 910, Epoch: 1, d_loss: 0.026238955577103817, g_loss: 4.362578963237588\n",
            "Iter: 920, Epoch: 1, d_loss: 0.30263515111534744, g_loss: 2.7228099679940803\n",
            "Iter: 930, Epoch: 1, d_loss: 0.12140245183403184, g_loss: 2.5688502567682803\n",
            "Iter: 940, Epoch: 1, d_loss: 0.12226147394617556, g_loss: 2.7444480248878262\n",
            "Iter: 950, Epoch: 1, d_loss: 0.05953185127821585, g_loss: 3.6702953240598775\n",
            "Iter: 960, Epoch: 1, d_loss: 0.03939604153013028, g_loss: 3.737978543809743\n",
            "Iter: 970, Epoch: 1, d_loss: 0.04530030079180934, g_loss: 3.981809193676171\n",
            "Iter: 980, Epoch: 1, d_loss: 0.059893779377392306, g_loss: 3.8651306174249216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ai/graph.py:155: RuntimeWarning: divide by zero encountered in log\n",
            "  out = ai.parameter.Parameter(data=np.log(h.data), graph=self)\n",
            "/usr/local/lib/python3.6/dist-packages/ai/graph.py:75: RuntimeWarning: invalid value encountered in multiply\n",
            "  out = ai.parameter.Parameter(data=np.multiply(x.data, y.data), graph=self)\n",
            "/usr/local/lib/python3.6/dist-packages/ai/graph.py:161: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  h.grad += np.multiply(out.grad, np.divide(1.0, h.data))\n",
            "/usr/local/lib/python3.6/dist-packages/ai/graph.py:161: RuntimeWarning: invalid value encountered in multiply\n",
            "  h.grad += np.multiply(out.grad, np.divide(1.0, h.data))\n",
            "/usr/local/lib/python3.6/dist-packages/ai/graph.py:546: RuntimeWarning: invalid value encountered in less\n",
            "  z.grad[z.data < 0] *= alpha\n",
            "/usr/local/lib/python3.6/dist-packages/ai/graph.py:528: RuntimeWarning: invalid value encountered in less\n",
            "  z.grad[z.data < 0] = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iter: 990, Epoch: 1, d_loss: nan, g_loss: nan\n",
            "Iter: 1000, Epoch: 1, d_loss: nan, g_loss: nan\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Discriminator.npy\n",
            "Iter: 1010, Epoch: 1, d_loss: nan, g_loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-bf64fa46b624>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mfake_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mfake_labels\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-5bffd95f8b7d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mo1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgf_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mo2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_bn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mo3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_bn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_deconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mo4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_bn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_deconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mo5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_bn4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_deconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/convolutional.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# easy callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/convolutional.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# convolution transpose operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_transpose2d_faster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# adding bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/graph.py\u001b[0m in \u001b[0;36mconv_transpose2d_faster\u001b[0;34m(self, x, K, s, p, a)\u001b[0m\n\u001b[1;32m    387\u001b[0m                 \u001b[0;31m# computing output image feature map by convolving across each element of input feature map with kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                 \u001b[0mpad_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;31m# cutting the padded portion from the input-feature-map's gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}