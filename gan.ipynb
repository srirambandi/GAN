{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "gan.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirambandi/GAN/blob/master/gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RTzsFdfJn69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10b26b44-39da-4611-c085-b1bac8e11d1b"
      },
      "source": [
        "# when running in colab notebooks, first install library\n",
        "!pip install import-ai\n",
        "# upload respective dataset manually from examples directory of the library or download as below\n",
        "!apt install subversion\n",
        "!svn checkout https://github.com/srirambandi/ai/trunk/examples/MNIST"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import-ai\n",
            "  Downloading https://files.pythonhosted.org/packages/16/c9/61a99b75a3ccd70ddd207ea12e28b9baa17feba9fffb2d7181d03d1b8147/import_ai-1.3.11-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.6/dist-packages (from import-ai) (1.18.5)\n",
            "Collecting graphviz>=0.14\n",
            "  Downloading https://files.pythonhosted.org/packages/83/cc/c62100906d30f95d46451c15eb407da7db201e30f42008f3643945910373/graphviz-0.14-py2.py3-none-any.whl\n",
            "Installing collected packages: graphviz, import-ai\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.14 import-ai-1.3.11\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libapr1 libaprutil1 libserf-1-1 libsvn1\n",
            "Suggested packages:\n",
            "  db5.3-util libapache2-mod-svn subversion-tools\n",
            "The following NEW packages will be installed:\n",
            "  libapr1 libaprutil1 libserf-1-1 libsvn1 subversion\n",
            "0 upgraded, 5 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 2,237 kB of archives.\n",
            "After this operation, 9,910 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libapr1 amd64 1.6.3-2 [90.9 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libaprutil1 amd64 1.6.1-2 [84.4 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libserf-1-1 amd64 1.3.9-6 [44.4 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsvn1 amd64 1.9.7-4ubuntu1 [1,183 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 subversion amd64 1.9.7-4ubuntu1 [834 kB]\n",
            "Fetched 2,237 kB in 1s (2,447 kB/s)\n",
            "Selecting previously unselected package libapr1:amd64.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../libapr1_1.6.3-2_amd64.deb ...\n",
            "Unpacking libapr1:amd64 (1.6.3-2) ...\n",
            "Selecting previously unselected package libaprutil1:amd64.\n",
            "Preparing to unpack .../libaprutil1_1.6.1-2_amd64.deb ...\n",
            "Unpacking libaprutil1:amd64 (1.6.1-2) ...\n",
            "Selecting previously unselected package libserf-1-1:amd64.\n",
            "Preparing to unpack .../libserf-1-1_1.3.9-6_amd64.deb ...\n",
            "Unpacking libserf-1-1:amd64 (1.3.9-6) ...\n",
            "Selecting previously unselected package libsvn1:amd64.\n",
            "Preparing to unpack .../libsvn1_1.9.7-4ubuntu1_amd64.deb ...\n",
            "Unpacking libsvn1:amd64 (1.9.7-4ubuntu1) ...\n",
            "Selecting previously unselected package subversion.\n",
            "Preparing to unpack .../subversion_1.9.7-4ubuntu1_amd64.deb ...\n",
            "Unpacking subversion (1.9.7-4ubuntu1) ...\n",
            "Setting up libapr1:amd64 (1.6.3-2) ...\n",
            "Setting up libaprutil1:amd64 (1.6.1-2) ...\n",
            "Setting up libserf-1-1:amd64 (1.3.9-6) ...\n",
            "Setting up libsvn1:amd64 (1.9.7-4ubuntu1) ...\n",
            "Setting up subversion (1.9.7-4ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "A    MNIST/test.npy\n",
            "A    MNIST/train.npy\n",
            "Checked out revision 120.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW4HapEUesLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e8f28aa4-4eb7-43c4-e874-8b1d82097396"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY0FMFMLJlgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ai\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNYfGAkfJlgY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_dim = 100\n",
        "gf_dim = 64\n",
        "df_dim = 64"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiFy00xkJ3X1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ai.manual_seed(2357)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ3zS_s-Jlgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(m):\n",
        "    train_dict = np.load('MNIST/train.npy', allow_pickle=True)\n",
        "    test_dict = np.load('MNIST/test.npy', allow_pickle=True)\n",
        "    data = np.concatenate([train_dict.item()['data'], test_dict.item()['data']])\n",
        "    data = data.transpose(1, 2, 0)   # making data batch-last\n",
        "    data = data.reshape(1, *data.shape) / 127.5 - 1.   # adding channel dimension and normalizing data\n",
        "    epoch = 2\n",
        "    \n",
        "    while True:\n",
        "        epoch += 1\n",
        "        for batch in range(int(data.shape[-1] / m)):\n",
        "            yield data[...,batch * m:(batch + 1) * m], epoch"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsEHzfzVJlgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(ai.Module):\n",
        "    def __init__(self):\n",
        "        self.g_fc = ai.Linear(z_dim, 8*gf_dim * 2 * 2)\n",
        "        self.g_bn1 = ai.BatchNorm((8*gf_dim, 2, 2))\n",
        "        self.g_deconv1 = ai.ConvTranspose2d(8*gf_dim, 4*gf_dim, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        self.g_bn2 = ai.BatchNorm((4*gf_dim, 4, 4))\n",
        "        self.g_deconv2 = ai.ConvTranspose2d(4*gf_dim, 2*gf_dim, kernel_size=5, stride=2, padding=2, a=0)\n",
        "        self.g_bn3 = ai.BatchNorm((2*gf_dim, 7, 7))\n",
        "        self.g_deconv3 = ai.ConvTranspose2d(2*gf_dim, gf_dim, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        self.g_bn4 = ai.BatchNorm((gf_dim, 14, 14))\n",
        "        self.g_deconv4 = ai.ConvTranspose2d(gf_dim, 1, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        \n",
        "    def forward(self, z):\n",
        "        o1 = ai.G.reshape(self.g_fc(z), (8*gf_dim, 2, 2))\n",
        "        o2 = ai.G.relu(self.g_bn1(o1))\n",
        "        o3 = ai.G.relu(self.g_bn2(self.g_deconv1(o2)))\n",
        "        o4 = ai.G.relu(self.g_bn3(self.g_deconv2(o3)))\n",
        "        o5 = ai.G.relu(self.g_bn4(self.g_deconv3(o4)))\n",
        "        fake_image = ai.G.tanh(self.g_deconv4(o5))\n",
        "        return fake_image"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nG_7CSfJlgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(ai.Module):\n",
        "    def __init__(self):\n",
        "        self.d_conv1 = ai.Conv2d(1, 64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_conv2 = ai.Conv2d(64, 2*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn1 = ai.BatchNorm((2*64, 7, 7))\n",
        "        self.d_conv3 = ai.Conv2d(2*64, 3*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn2 = ai.BatchNorm((3*64, 4, 4))\n",
        "        self.d_conv4 = ai.Conv2d(3*64, 4*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn3 = ai.BatchNorm((4*64, 2, 2))\n",
        "        self.d_fc = ai.Linear(1024, 1)\n",
        "        \n",
        "    def forward(self, image):\n",
        "        o1 = ai.G.lrelu(self.d_conv1(image))\n",
        "        o2 = ai.G.lrelu(self.d_bn1(self.d_conv2(o1)))\n",
        "        o3 = ai.G.lrelu(self.d_bn2(self.d_conv3(o2)))\n",
        "        o4 = ai.G.lrelu(self.d_bn3(self.d_conv4(o3)))\n",
        "        o5 = self.d_fc(o4)\n",
        "        return ai.G.sigmoid(o5)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l88SAS6rJlgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "fdb7b0ec-c652-48c2-e584-73d146660c2e"
      },
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "generator.load('/content/drive/My Drive/GAN/Generator.npy')\n",
        "discriminator.load('/content/drive/My Drive/GAN/Discriminator.npy')\n",
        "print(generator)\n",
        "print(discriminator)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading model...\n",
            "Successfully loaded model from /content/drive/My Drive/GAN/Generator.npy\n",
            "loading model...\n",
            "Successfully loaded model from /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Generator(\n",
            "  g_fc: Linear(input_features=100, output_features=2048, bias=True)\n",
            "  g_bn1: BatchNorm((512, 2, 2), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv1: ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            "  g_bn2: BatchNorm((256, 4, 4), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv2: ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(0, 0), bias=True)\n",
            "  g_bn3: BatchNorm((128, 7, 7), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv3: ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            "  g_bn4: BatchNorm((64, 14, 14), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv4: ConvTranspose2d(64, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            ")\n",
            "Discriminator(\n",
            "  d_conv1: Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_conv2: Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn1: BatchNorm((128, 7, 7), axis=-1, momentum=0.9, bias=True)\n",
            "  d_conv3: Conv2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn2: BatchNorm((192, 4, 4), axis=-1, momentum=0.9, bias=True)\n",
            "  d_conv4: Conv2d(192, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn3: BatchNorm((256, 2, 2), axis=-1, momentum=0.9, bias=True)\n",
            "  d_fc: Linear(input_features=1024, output_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md_IEa9CJlgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "L = ai.Loss(loss_fn='BCELoss')\n",
        "g_optim = ai.Optimizer(generator.parameters(), optim_fn='Adam', lr=lr, beta1=beta1)\n",
        "d_optim = ai.Optimizer(discriminator.parameters(), optim_fn='Adam', lr=lr, beta1=beta1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsfYfCeuJlg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it, epoch = 0, 0\n",
        "m = 64   # batch size\n",
        "n_discriminator = 1   # number of descriminator updates per generator update\n",
        "\n",
        "# real images data generator\n",
        "data = data_generator(m)\n",
        "\n",
        "sample_z = np.random.uniform(-1, 1, (z_dim, m))\n",
        "sampled_images = np.load('/content/drive/My Drive/GAN/sampled_images.npy')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-6QzGr9Jlg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampler(sampled_images):\n",
        "    ai.G.grad_mode = False\n",
        "\n",
        "    # generate images like real data\n",
        "    fake_images = generator.forward(sample_z).data\n",
        "    fake_images = (fake_images + 1.) / 2.\n",
        "\n",
        "    if sampled_images is not None:\n",
        "        sampled_images = np.concatenate([sampled_images, fake_images], axis=-1)\n",
        "    else:\n",
        "        sampled_images = fake_images\n",
        "    \n",
        "    ai.G.grad_mode = True\n",
        "\n",
        "    return sampled_images"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUKbYB9EJlg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d374d46-fb54-46fe-ada1-5cc49f883e96"
      },
      "source": [
        "for it in range(1401, 10000):\n",
        "    \n",
        "    # freeze generator before optimizing descriminator\n",
        "    for p in generator.parameters():\n",
        "        p.eval_grad = False\n",
        "\n",
        "    # training descriminator to identify real/fake data\n",
        "    for _ in range(n_discriminator):\n",
        "\n",
        "        real_images, epoch = data.__next__()\n",
        "        real_labels = np.ones((1, m))\n",
        "        if (real_images.shape[-1] != m):\n",
        "            continue\n",
        "\n",
        "        real_probs = discriminator.forward(real_images)\n",
        "        d_loss_real = L.loss(real_probs, real_labels)\n",
        "\n",
        "        z = np.random.randn(z_dim, m)\n",
        "        fake_images = generator.forward(z)\n",
        "        fake_labels =  np.zeros((1, m))\n",
        "\n",
        "        fake_probs = discriminator.forward(fake_images)\n",
        "        d_loss_fake = L.loss(fake_probs, fake_labels)\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.grad = np.zeros(d_loss.shape)\n",
        "\n",
        "        d_loss.backward()\n",
        "        d_optim.step()\n",
        "        d_optim.zero_grad()\n",
        "\n",
        "    # unfreeze generator\n",
        "    for p in generator.parameters():\n",
        "        p.eval_grad = True\n",
        "\n",
        "    # training generator to fool descriminator with fake data\n",
        "    z = np.random.uniform(-1, 1, (z_dim, m))\n",
        "    fake_images = generator.forward(z)\n",
        "    fake_labels =  np.ones((1, m))\n",
        "\n",
        "    fake_probs = discriminator.forward(fake_images)\n",
        "    g_loss = L.loss(fake_probs, fake_labels)\n",
        "\n",
        "    g_loss.backward()\n",
        "    g_optim.step()\n",
        "    g_optim.zero_grad()\n",
        "    d_optim.zero_grad()\n",
        "\n",
        "    if it%10 == 0:\n",
        "        print('Iter: {}, Epoch: {}, d_loss: {}, g_loss: {}'.format(it, epoch, d_loss.data[0, 0], g_loss.data[0, 0]))\n",
        "    \n",
        "    if it%100 == 0:\n",
        "        sampled_images=sampler(sampled_images)\n",
        "        np.save('/content/drive/My Drive/GAN/sampled_images.npy', sampled_images)\n",
        "        generator.save('/content/drive/My Drive/GAN/Generator.npy')\n",
        "        discriminator.save('/content/drive/My Drive/GAN/Discriminator.npy')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using Adam\n",
            "using Adam\n",
            "Iter: 1410, Epoch: 3, d_loss: 0.448113872106131, g_loss: 1.993288838901529\n",
            "Iter: 1420, Epoch: 3, d_loss: 1.5692678239254383, g_loss: 3.365529773145646\n",
            "Iter: 1430, Epoch: 3, d_loss: 0.4387115884879439, g_loss: 2.6846201559150646\n",
            "Iter: 1440, Epoch: 3, d_loss: 0.3020842479260754, g_loss: 3.423397632123343\n",
            "Iter: 1450, Epoch: 3, d_loss: 0.14103987211601543, g_loss: 2.9940780875617894\n",
            "Iter: 1460, Epoch: 3, d_loss: 0.22994941725153342, g_loss: 3.0527082892769855\n",
            "Iter: 1470, Epoch: 3, d_loss: 0.1804811458701654, g_loss: 2.197844609443718\n",
            "Iter: 1480, Epoch: 3, d_loss: 0.281712029406855, g_loss: 2.408337338086004\n",
            "Iter: 1490, Epoch: 3, d_loss: 0.39794025022881524, g_loss: 2.862531885197512\n",
            "Iter: 1500, Epoch: 3, d_loss: 0.1217300703183426, g_loss: 2.58334655340635\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 1510, Epoch: 3, d_loss: 0.11216670723835633, g_loss: 2.7881341286661367\n",
            "Iter: 1520, Epoch: 3, d_loss: 0.4647599217866023, g_loss: 2.6258242715485625\n",
            "Iter: 1530, Epoch: 3, d_loss: 0.25215202891874455, g_loss: 3.0673853357674408\n",
            "Iter: 1540, Epoch: 3, d_loss: 0.33284206913340386, g_loss: 2.861001319358681\n",
            "Iter: 1550, Epoch: 3, d_loss: 0.32562264873899516, g_loss: 2.414730881985165\n",
            "Iter: 1560, Epoch: 3, d_loss: 0.23394785771307247, g_loss: 3.224639562734931\n",
            "Iter: 1570, Epoch: 3, d_loss: 0.3245255147866773, g_loss: 4.049038039945163\n",
            "Iter: 1580, Epoch: 3, d_loss: 0.10813262518951545, g_loss: 4.355315397024877\n",
            "Iter: 1590, Epoch: 3, d_loss: 0.3547688400154848, g_loss: 3.6269258871604175\n",
            "Iter: 1600, Epoch: 3, d_loss: 0.35442073687007397, g_loss: 2.6111976660188225\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 1610, Epoch: 3, d_loss: 0.14688002053345758, g_loss: 3.165495200986039\n",
            "Iter: 1620, Epoch: 3, d_loss: 0.8458155367430995, g_loss: 2.4214300920963483\n",
            "Iter: 1630, Epoch: 3, d_loss: 1.3337788310400438, g_loss: 2.0903133929174964\n",
            "Iter: 1640, Epoch: 3, d_loss: 0.17249366041440078, g_loss: 3.7170972371907287\n",
            "Iter: 1650, Epoch: 3, d_loss: 0.4293423798965176, g_loss: 3.120985904454163\n",
            "Iter: 1660, Epoch: 3, d_loss: 0.28967548490850514, g_loss: 2.709642679968724\n",
            "Iter: 1670, Epoch: 3, d_loss: 0.41739785371069343, g_loss: 3.873813669112692\n",
            "Iter: 1680, Epoch: 3, d_loss: 0.4686572360886171, g_loss: 1.563820237771498\n",
            "Iter: 1690, Epoch: 3, d_loss: 0.46422321022884805, g_loss: 3.1575407896934067\n",
            "Iter: 1700, Epoch: 3, d_loss: 0.3123385853681359, g_loss: 2.2518579790901865\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 1710, Epoch: 3, d_loss: 0.9181702810474993, g_loss: 2.61038910822704\n",
            "Iter: 1720, Epoch: 3, d_loss: 0.23169925679703848, g_loss: 1.2954237446881942\n",
            "Iter: 1730, Epoch: 3, d_loss: 0.3089129494770203, g_loss: 2.0993969987777708\n",
            "Iter: 1740, Epoch: 3, d_loss: 0.31953005232419407, g_loss: 3.426481418387515\n",
            "Iter: 1750, Epoch: 3, d_loss: 0.3625000549906401, g_loss: 1.9837601239144378\n",
            "Iter: 1760, Epoch: 3, d_loss: 0.2866026309368508, g_loss: 3.0335208367778725\n",
            "Iter: 1770, Epoch: 3, d_loss: 0.32408125885836847, g_loss: 1.1545724418721168\n",
            "Iter: 1780, Epoch: 3, d_loss: 0.4742308467730294, g_loss: 2.4488704489112387\n",
            "Iter: 1790, Epoch: 3, d_loss: 0.3068487548246229, g_loss: 2.9842028991331144\n",
            "Iter: 1800, Epoch: 3, d_loss: 0.5429723929301751, g_loss: 2.1798212320856702\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 1810, Epoch: 3, d_loss: 0.3380384186841811, g_loss: 3.0025534121515425\n",
            "Iter: 1820, Epoch: 3, d_loss: 0.31398860623903446, g_loss: 4.414575423350949\n",
            "Iter: 1830, Epoch: 3, d_loss: 0.4819956029579294, g_loss: 2.7016180170027253\n",
            "Iter: 1840, Epoch: 3, d_loss: 0.5534146116449583, g_loss: 2.719298214145509\n",
            "Iter: 1850, Epoch: 3, d_loss: 0.5709549920228576, g_loss: 3.153958357628927\n",
            "Iter: 1860, Epoch: 3, d_loss: 0.4795893229520276, g_loss: 2.3166266822406065\n",
            "Iter: 1870, Epoch: 3, d_loss: 0.9510231114330239, g_loss: 1.5537000269746717\n",
            "Iter: 1880, Epoch: 3, d_loss: 0.28741700260146463, g_loss: 2.073738741982266\n",
            "Iter: 1890, Epoch: 3, d_loss: 1.0611208797012823, g_loss: 1.9418173738084255\n",
            "Iter: 1900, Epoch: 3, d_loss: 0.3207416178288329, g_loss: 1.9667481674400507\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 1910, Epoch: 3, d_loss: 0.5496328151963916, g_loss: 1.980938065987655\n",
            "Iter: 1920, Epoch: 3, d_loss: 0.5288881778884232, g_loss: 2.7974389360315772\n",
            "Iter: 1930, Epoch: 3, d_loss: 0.46374327531611986, g_loss: 2.064542528105302\n",
            "Iter: 1940, Epoch: 3, d_loss: 0.3195100457632105, g_loss: 2.1479711779560815\n",
            "Iter: 1950, Epoch: 3, d_loss: 0.8619905716935763, g_loss: 1.8360576100978476\n",
            "Iter: 1960, Epoch: 3, d_loss: 0.5013710324217333, g_loss: 1.0546447451017735\n",
            "Iter: 1970, Epoch: 3, d_loss: 0.42254948330529807, g_loss: 2.9141405320840073\n",
            "Iter: 1980, Epoch: 3, d_loss: 0.33532558275487045, g_loss: 1.765782681807833\n",
            "Iter: 1990, Epoch: 3, d_loss: 0.6788035248703304, g_loss: 1.5692626506042067\n",
            "Iter: 2000, Epoch: 3, d_loss: 0.6097949317634952, g_loss: 1.797956462875572\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 2010, Epoch: 3, d_loss: 0.3714796736742673, g_loss: 2.153282727348756\n",
            "Iter: 2020, Epoch: 3, d_loss: 0.7986315522802124, g_loss: 2.402459494224123\n",
            "Iter: 2030, Epoch: 3, d_loss: 0.35369236541110294, g_loss: 1.71253675890099\n",
            "Iter: 2040, Epoch: 3, d_loss: 0.4687530412399287, g_loss: 1.3796503117264987\n",
            "Iter: 2050, Epoch: 3, d_loss: 0.4917824909811628, g_loss: 2.22565469496342\n",
            "Iter: 2060, Epoch: 3, d_loss: 0.37396572384146953, g_loss: 2.4724259781003597\n",
            "Iter: 2070, Epoch: 3, d_loss: 0.34350476518110795, g_loss: 2.280272534102074\n",
            "Iter: 2080, Epoch: 3, d_loss: 0.23145464676507127, g_loss: 2.574010754095359\n",
            "Iter: 2090, Epoch: 3, d_loss: 0.6724404530713739, g_loss: 1.3510300376104272\n",
            "Iter: 2100, Epoch: 3, d_loss: 0.4470427294037255, g_loss: 1.573775508009797\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 2110, Epoch: 3, d_loss: 0.42440446518072006, g_loss: 2.004817508898334\n",
            "Iter: 2120, Epoch: 3, d_loss: 0.4074841800730858, g_loss: 2.9763840734639855\n",
            "Iter: 2130, Epoch: 3, d_loss: 0.3119099179301914, g_loss: 2.0790173202221163\n",
            "Iter: 2140, Epoch: 3, d_loss: 0.4325141432156367, g_loss: 0.6346871114345438\n",
            "Iter: 2150, Epoch: 3, d_loss: 0.4204937571447167, g_loss: 2.597655901840654\n",
            "Iter: 2160, Epoch: 3, d_loss: 0.5328851105661169, g_loss: 2.195967966897133\n",
            "Iter: 2170, Epoch: 3, d_loss: 0.4172806466129652, g_loss: 3.363852673498881\n",
            "Iter: 2180, Epoch: 3, d_loss: 0.30025699155753965, g_loss: 1.6215343619271214\n",
            "Iter: 2190, Epoch: 3, d_loss: 0.5882902040618136, g_loss: 1.9485764877066094\n",
            "Iter: 2200, Epoch: 3, d_loss: 0.552467863838368, g_loss: 2.2347100277317544\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 2210, Epoch: 3, d_loss: 0.3464364593662811, g_loss: 2.3120962430442864\n",
            "Iter: 2220, Epoch: 3, d_loss: 0.7519772284092685, g_loss: 1.9819556762686728\n",
            "Iter: 2230, Epoch: 3, d_loss: 0.6563711486999669, g_loss: 1.955357802997145\n",
            "Iter: 2240, Epoch: 3, d_loss: 0.6495872699139014, g_loss: 1.9253366275122008\n",
            "Iter: 2250, Epoch: 3, d_loss: 0.39221530780841474, g_loss: 1.0594565330068035\n",
            "Iter: 2260, Epoch: 3, d_loss: 0.3819737430138463, g_loss: 2.7496087497217268\n",
            "Iter: 2270, Epoch: 3, d_loss: 0.9136830484963211, g_loss: 2.4572116394985115\n",
            "Iter: 2280, Epoch: 3, d_loss: 0.46469280808776375, g_loss: 1.5055878030706202\n",
            "Iter: 2290, Epoch: 3, d_loss: 0.4639232079940865, g_loss: 1.8062102558999553\n",
            "Iter: 2300, Epoch: 3, d_loss: 0.32502475400052866, g_loss: 1.7977082178983466\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 2310, Epoch: 3, d_loss: 0.5001586920969403, g_loss: 2.659027704033437\n",
            "Iter: 2320, Epoch: 3, d_loss: 0.6797856349078568, g_loss: 2.2657953774034536\n",
            "Iter: 2330, Epoch: 3, d_loss: 0.6162382645228002, g_loss: 1.8428782025228438\n",
            "Iter: 2340, Epoch: 3, d_loss: 0.4252156123175115, g_loss: 2.379517239069168\n",
            "Iter: 2350, Epoch: 3, d_loss: 0.41725778419661746, g_loss: 2.367870608869209\n",
            "Iter: 2360, Epoch: 3, d_loss: 0.5687066090657666, g_loss: 2.5184711804055\n",
            "Iter: 2370, Epoch: 3, d_loss: 0.23165376410618618, g_loss: 2.215495550723366\n",
            "Iter: 2380, Epoch: 3, d_loss: 0.3087022543190081, g_loss: 1.9644188783875638\n",
            "Iter: 2390, Epoch: 3, d_loss: 0.26602357126556697, g_loss: 1.571341811104613\n",
            "Iter: 2400, Epoch: 3, d_loss: 0.3665909430944967, g_loss: 1.7403779954398007\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 2410, Epoch: 3, d_loss: 0.25283323628043697, g_loss: 2.0511150269043723\n",
            "Iter: 2420, Epoch: 3, d_loss: 0.29487787572428475, g_loss: 2.765981152747917\n",
            "Iter: 2430, Epoch: 3, d_loss: 0.3185672265671401, g_loss: 2.540309618593653\n",
            "Iter: 2440, Epoch: 3, d_loss: 0.8595650085141963, g_loss: 2.8597187417512173\n",
            "Iter: 2450, Epoch: 3, d_loss: 0.6164032524675832, g_loss: 1.7204012671304028\n",
            "Iter: 2460, Epoch: 3, d_loss: 0.40570537029977305, g_loss: 2.3133763159131893\n",
            "Iter: 2470, Epoch: 3, d_loss: 0.3794320259128705, g_loss: 2.85047558299381\n",
            "Iter: 2480, Epoch: 3, d_loss: 0.733026724573238, g_loss: 2.6145636354552804\n",
            "Iter: 2490, Epoch: 3, d_loss: 0.5293458250807852, g_loss: 3.1716913566700753\n",
            "Iter: 2500, Epoch: 4, d_loss: 0.3690896053014345, g_loss: 2.83993654371159\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 2510, Epoch: 4, d_loss: 0.2967392133593923, g_loss: 3.1818852421660857\n",
            "Iter: 2520, Epoch: 4, d_loss: 0.44286069104738324, g_loss: 2.1036279617699374\n",
            "Iter: 2530, Epoch: 4, d_loss: 0.2775970283497328, g_loss: 3.435205320045267\n",
            "Iter: 2540, Epoch: 4, d_loss: 0.16904115791154395, g_loss: 3.6632451363306484\n",
            "Iter: 2550, Epoch: 4, d_loss: 0.3882068959442572, g_loss: 2.1626867513322323\n",
            "Iter: 2560, Epoch: 4, d_loss: 0.43250461690562536, g_loss: 3.0448562923834626\n",
            "Iter: 2570, Epoch: 4, d_loss: 0.4804875844221961, g_loss: 2.3132051289886597\n",
            "Iter: 2580, Epoch: 4, d_loss: 0.717500946124265, g_loss: 1.6645315331388686\n",
            "Iter: 2590, Epoch: 4, d_loss: 0.3062702143505797, g_loss: 3.0675108197074623\n",
            "Iter: 2600, Epoch: 4, d_loss: 0.32970812620668455, g_loss: 2.6240174735280086\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 2610, Epoch: 4, d_loss: 0.313873826807996, g_loss: 2.6592248407929824\n",
            "Iter: 2620, Epoch: 4, d_loss: 0.27025391221892214, g_loss: 2.6096004429700668\n",
            "Iter: 2630, Epoch: 4, d_loss: 0.5141769293719181, g_loss: 1.3372503599088343\n",
            "Iter: 2640, Epoch: 4, d_loss: 0.375231612764643, g_loss: 1.7387450366478983\n",
            "Iter: 2650, Epoch: 4, d_loss: 0.3678783012667613, g_loss: 2.2283891275568912\n",
            "Iter: 2660, Epoch: 4, d_loss: 0.4342728450894332, g_loss: 2.814427839559343\n",
            "Iter: 2670, Epoch: 4, d_loss: 0.3427791742222166, g_loss: 2.3037195235096974\n",
            "Iter: 2680, Epoch: 4, d_loss: 0.26803221933728355, g_loss: 3.225541332599219\n",
            "Iter: 2690, Epoch: 4, d_loss: 0.2434663300144374, g_loss: 3.3295054716350276\n",
            "Iter: 2700, Epoch: 4, d_loss: 0.4035022649740529, g_loss: 2.3687847079453324\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n",
            "Iter: 2710, Epoch: 4, d_loss: 0.1464728069674206, g_loss: 1.8271581151028748\n",
            "Iter: 2720, Epoch: 4, d_loss: 0.26303421583684705, g_loss: 1.5655710876651177\n",
            "Iter: 2730, Epoch: 4, d_loss: 0.556033642266835, g_loss: 1.935686855770288\n",
            "Iter: 2740, Epoch: 4, d_loss: 0.3124375985077211, g_loss: 1.8408753985958826\n",
            "Iter: 2750, Epoch: 4, d_loss: 0.42730780484214426, g_loss: 1.3894251530554005\n",
            "Iter: 2760, Epoch: 4, d_loss: 0.19093589652211895, g_loss: 3.4440308625211333\n",
            "Iter: 2770, Epoch: 4, d_loss: 0.4939855973488577, g_loss: 3.0134975120302654\n",
            "Iter: 2780, Epoch: 4, d_loss: 0.2836652584674001, g_loss: 4.038275435147394\n",
            "Iter: 2790, Epoch: 4, d_loss: 0.29922284212154576, g_loss: 2.1969774230643004\n",
            "Iter: 2800, Epoch: 4, d_loss: 0.17862572460009207, g_loss: 2.3468802698701947\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in /content/drive/My Drive/GAN/Discriminator.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-cc5f13334c63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0md_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0md_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/parameter.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, to)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_node_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backprop_op'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# executing the back-propagation operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/graph.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;31m# return (K.grad, x.grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'func'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'conv2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'backprop_op'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/graph.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                             \u001b[0mpad_x_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                     \u001b[0;31m# cutting the padded portion from the input-feature-map's gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2229\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}