{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "wgan.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirambandi/GAN/blob/master/wgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk-FsI3wcrMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# when running in colab notebooks, first install library\n",
        "!pip install import-ai\n",
        "# upload respective dataset manually from examples directory of the library or download as below\n",
        "!apt install subversion\n",
        "!svn checkout https://github.com/srirambandi/ai/trunk/examples/MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bql-uXp0cqPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ai\n",
        "import numpy as np"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unwx_Hc1cqPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_dim = 100\n",
        "gf_dim = 64\n",
        "df_dim = 64"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQzdpXIpcyL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ai.manual_seed(2357)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBgfrdNzcqPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(m):\n",
        "    train_dict = np.load('MNIST/train.npy', allow_pickle=True)\n",
        "    test_dict = np.load('MNIST/test.npy', allow_pickle=True)\n",
        "    data = np.concatenate([train_dict.item()['data'], test_dict.item()['data']])\n",
        "    data = data.transpose(1, 2, 0)   # making data batch-last\n",
        "    data = data.reshape(1, *data.shape) / 255   # adding channel dimension and normalizing data\n",
        "    \n",
        "    while True:\n",
        "        for batch in range(int(data.shape[-1] / m)):\n",
        "            yield data[...,batch * m:(batch + 1) * m]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juS9j_gScqPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(ai.Module):\n",
        "    def __init__(self):\n",
        "        self.g_fc = ai.Linear(z_dim, 8*gf_dim * 2 * 2)\n",
        "        self.g_bn1 = ai.BatchNorm((8*gf_dim, 2, 2))\n",
        "        self.g_deconv1 = ai.ConvTranspose2d(8*gf_dim, 4*gf_dim, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        self.g_bn2 = ai.BatchNorm((4*gf_dim, 4, 4))\n",
        "        self.g_deconv2 = ai.ConvTranspose2d(4*gf_dim, 2*gf_dim, kernel_size=5, stride=2, padding=2, a=0)\n",
        "        self.g_bn3 = ai.BatchNorm((2*gf_dim, 7, 7))\n",
        "        self.g_deconv3 = ai.ConvTranspose2d(2*gf_dim, gf_dim, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        self.g_bn4 = ai.BatchNorm((gf_dim, 14, 14))\n",
        "        self.g_deconv4 = ai.ConvTranspose2d(gf_dim, 1, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        \n",
        "    def forward(self, z):\n",
        "        o1 = ai.G.reshape(self.g_fc(z), (8*gf_dim, 2, 2))\n",
        "        o2 = ai.G.relu(self.g_bn1(o1))\n",
        "        o3 = ai.G.relu(self.g_bn2(self.g_deconv1(o2)))\n",
        "        o4 = ai.G.relu(self.g_bn3(self.g_deconv2(o3)))\n",
        "        o5 = ai.G.relu(self.g_bn4(self.g_deconv3(o4)))\n",
        "        fake_image = ai.G.tanh(self.g_deconv4(o5))\n",
        "        return fake_image"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPElqs6gcqPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(ai.Module):\n",
        "    def __init__(self):\n",
        "        self.d_conv1 = ai.Conv2d(1, 64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_conv2 = ai.Conv2d(64, 2*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn1 = ai.BatchNorm((2*64, 7, 7), axis=0)\n",
        "        self.d_conv3 = ai.Conv2d(2*64, 3*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn2 = ai.BatchNorm((3*64, 4, 4), axis=0)\n",
        "        self.d_conv4 = ai.Conv2d(3*64, 4*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn3 = ai.BatchNorm((4*64, 2, 2), axis=0)\n",
        "        self.d_fc = ai.Linear(1024, 1)\n",
        "        \n",
        "    def forward(self, image):\n",
        "        o1 = ai.G.lrelu(self.d_conv1(image))\n",
        "        o2 = ai.G.lrelu(self.d_bn1(self.d_conv2(o1)))\n",
        "        o3 = ai.G.lrelu(self.d_bn2(self.d_conv3(o2)))\n",
        "        o4 = ai.G.lrelu(self.d_bn3(self.d_conv4(o3)))\n",
        "        o5 = self.d_fc(o4)\n",
        "        return o5"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50IAOgjXcqPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "217441d4-70b2-4826-db60-f982f96ebe63"
      },
      "source": [
        "generator = Generator()\n",
        "critic = Critic()\n",
        "print(generator)\n",
        "print(critic)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  g_fc: Linear(input_features=100, output_features=2048, bias=True)\n",
            "  g_bn1: BatchNorm((512, 2, 2), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv1: ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            "  g_bn2: BatchNorm((256, 4, 4), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv2: ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(0, 0), bias=True)\n",
            "  g_bn3: BatchNorm((128, 7, 7), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv3: ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            "  g_bn4: BatchNorm((64, 14, 14), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv4: ConvTranspose2d(64, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            ")\n",
            "Critic(\n",
            "  d_conv1: Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_conv2: Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn1: BatchNorm((128, 7, 7), axis=0, momentum=0.9, bias=True)\n",
            "  d_conv3: Conv2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn2: BatchNorm((192, 4, 4), axis=0, momentum=0.9, bias=True)\n",
            "  d_conv4: Conv2d(192, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn3: BatchNorm((256, 2, 2), axis=0, momentum=0.9, bias=True)\n",
            "  d_fc: Linear(input_features=1024, output_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYbbyJZBcqPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.00005\n",
        "c = 0.01\n",
        "g_optim = ai.Optimizer(generator.parameters(), optim_fn='RMSProp', lr=lr)\n",
        "c_optim = ai.Optimizer(critic.parameters(), optim_fn='RMSProp', lr=lr)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRh7R4j1cqP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it, epoch = 0, 0\n",
        "m = 64   # batch size\n",
        "n_critic = 5   # number of critic updates per generator update\n",
        "data = data_generator(m)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLpbkD0LcqP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate():\n",
        "    ai.G.grad_mode = False\n",
        "\n",
        "    # generate images like real data\n",
        "    z = np.random.randn(z_dim, m)\n",
        "    fake_images = generator.forward(z)\n",
        "    \n",
        "    ai.G.grad_mode = True"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKaygbefcqQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5dab17bb-ea48-4882-aa66-295d4e87db80"
      },
      "source": [
        "while epoch < 10:\n",
        "    epoch += 1\n",
        "    it = 0\n",
        "\n",
        "    while it < int(70000/m):\n",
        "\n",
        "        # freeze generator before optimizing critic\n",
        "        for p in generator.parameters():\n",
        "            p.eval_grad = False\n",
        "\n",
        "        # training critic to identify real/fake data\n",
        "        for _ in range(n_critic):\n",
        "\n",
        "            real_images = data.__next__()\n",
        "            if (real_images.shape[-1] != m):\n",
        "                continue\n",
        "\n",
        "            c_loss_real = critic.forward(real_images)\n",
        "\n",
        "            z = np.random.randn(z_dim, m)\n",
        "            fake_images = generator.forward(z)\n",
        "\n",
        "            c_loss_fake = critic.forward(fake_images)\n",
        "\n",
        "            c_loss = c_loss_fake - c_loss_real\n",
        "            c_loss.grad = np.ones(c_loss.shape)\n",
        "\n",
        "            c_loss.backward()\n",
        "            c_optim.step()\n",
        "            c_optim.zero_grad()\n",
        "\n",
        "            ai.clip_grad_value(critic.parameters(), c)\n",
        "\n",
        "        # unfreeze generator\n",
        "        for p in generator.parameters():\n",
        "            p.eval_grad = True\n",
        "\n",
        "        # training generator to fool critic with fake data\n",
        "        z = np.random.randn(z_dim, m)\n",
        "        fake_images = generator.forward(z)\n",
        "\n",
        "        g_loss = critic.forward(fake_images)\n",
        "        neg_ones = ai.Parameter(data=-1.0 * np.ones(g_loss.shape), eval_grad=False)\n",
        "        g_loss = neg_ones * g_loss\n",
        "        g_loss.grad = np.ones(g_loss.shape)\n",
        "\n",
        "        g_loss.backward()\n",
        "        g_optim.step()\n",
        "        g_optim.zero_grad()\n",
        "        c_optim.zero_grad()\n",
        "\n",
        "        if it%n_critic == 0:\n",
        "            print('epoch: {}, iter: {}, c_loss: {}, g_loss: {}, sum_loss: {}'.format(epoch, it, c_loss.data[0, 0], g_loss.data[0, 0], (c_loss.data[0, 0] + g_loss.data[0, 0])))\n",
        "        it += n_critic\n",
        "    \n",
        "    print('Epoch {} completed. Accuracy: {}'.format(epoch, evaluate()))\n",
        "    generator.save()\n",
        "    critic.save()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using RMSProp\n",
            "using RMSProp\n",
            "epoch: 1, iter: 0, c_loss: -9.07990045436572, g_loss: 4.757166263191987, sum_loss: -4.322734191173733\n",
            "epoch: 1, iter: 5, c_loss: -11.487707827733491, g_loss: 5.790725942884189, sum_loss: -5.696981884849302\n",
            "epoch: 1, iter: 10, c_loss: -12.688327718970545, g_loss: 6.189182570681792, sum_loss: -6.499145148288752\n",
            "epoch: 1, iter: 15, c_loss: -13.019656377857666, g_loss: 6.470840926824807, sum_loss: -6.548815451032859\n",
            "epoch: 1, iter: 20, c_loss: -13.466302555942132, g_loss: 6.682575298866486, sum_loss: -6.783727257075646\n",
            "epoch: 1, iter: 25, c_loss: -13.61739275258413, g_loss: 6.690324745168354, sum_loss: -6.927068007415777\n",
            "epoch: 1, iter: 30, c_loss: -13.29561824440659, g_loss: 6.921312574957199, sum_loss: -6.374305669449392\n",
            "epoch: 1, iter: 35, c_loss: -13.79620181917478, g_loss: 7.088746233872638, sum_loss: -6.707455585302141\n",
            "epoch: 1, iter: 40, c_loss: -14.283329968878096, g_loss: 7.258086640374065, sum_loss: -7.025243328504031\n",
            "epoch: 1, iter: 45, c_loss: -14.72310541794912, g_loss: 7.31805942090615, sum_loss: -7.405045997042969\n",
            "epoch: 1, iter: 50, c_loss: -15.120562748725122, g_loss: 7.519351127970284, sum_loss: -7.601211620754839\n",
            "epoch: 1, iter: 55, c_loss: -15.41155001399453, g_loss: 7.677203995759619, sum_loss: -7.734346018234911\n",
            "epoch: 1, iter: 60, c_loss: -15.604245905437388, g_loss: 7.775791125781902, sum_loss: -7.828454779655486\n",
            "epoch: 1, iter: 65, c_loss: -15.951465521408185, g_loss: 7.910702472395313, sum_loss: -8.040763049012872\n",
            "epoch: 1, iter: 70, c_loss: -16.085893483005773, g_loss: 8.001012167335373, sum_loss: -8.0848813156704\n",
            "epoch: 1, iter: 75, c_loss: -16.477576840023282, g_loss: 8.153962453545626, sum_loss: -8.323614386477656\n",
            "epoch: 1, iter: 80, c_loss: -16.605795982517186, g_loss: 8.282967533992961, sum_loss: -8.322828448524225\n",
            "epoch: 1, iter: 85, c_loss: -16.936703746514464, g_loss: 8.393095067822506, sum_loss: -8.543608678691959\n",
            "epoch: 1, iter: 90, c_loss: -17.164275337610565, g_loss: 8.519344610222966, sum_loss: -8.6449307273876\n",
            "epoch: 1, iter: 95, c_loss: -17.430069864252424, g_loss: 8.635788266324157, sum_loss: -8.794281597928267\n",
            "epoch: 1, iter: 100, c_loss: -17.648062323555166, g_loss: 8.766064521862358, sum_loss: -8.881997801692808\n",
            "epoch: 1, iter: 105, c_loss: -17.900086307465273, g_loss: 8.871872694578343, sum_loss: -9.02821361288693\n",
            "epoch: 1, iter: 110, c_loss: -18.13764692989675, g_loss: 8.984097422395292, sum_loss: -9.153549507501458\n",
            "epoch: 1, iter: 115, c_loss: -18.32789933871795, g_loss: 9.116667740555398, sum_loss: -9.21123159816255\n",
            "epoch: 1, iter: 120, c_loss: -18.63083035585698, g_loss: 9.225058147783201, sum_loss: -9.405772208073778\n",
            "epoch: 1, iter: 125, c_loss: -18.863478638514724, g_loss: 9.350525121350474, sum_loss: -9.51295351716425\n",
            "epoch: 1, iter: 130, c_loss: -19.091802351116947, g_loss: 9.459754724340671, sum_loss: -9.632047626776275\n",
            "epoch: 1, iter: 135, c_loss: -19.339992871257845, g_loss: 9.580419889367079, sum_loss: -9.759572981890766\n",
            "epoch: 1, iter: 140, c_loss: -19.564146351323515, g_loss: 9.69917709774812, sum_loss: -9.864969253575396\n",
            "epoch: 1, iter: 145, c_loss: -19.78449194295002, g_loss: 9.82071234242251, sum_loss: -9.96377960052751\n",
            "epoch: 1, iter: 150, c_loss: -20.05303611442498, g_loss: 9.930863624905259, sum_loss: -10.122172489519722\n",
            "epoch: 1, iter: 155, c_loss: -20.28504251909835, g_loss: 10.047678320312022, sum_loss: -10.237364198786329\n",
            "epoch: 1, iter: 160, c_loss: -20.523793955213996, g_loss: 10.177728970592877, sum_loss: -10.346064984621119\n",
            "epoch: 1, iter: 165, c_loss: -20.765282356784155, g_loss: 10.292668600804474, sum_loss: -10.472613755979681\n",
            "epoch: 1, iter: 170, c_loss: -20.979317335187673, g_loss: 10.409081609337695, sum_loss: -10.570235725849978\n",
            "epoch: 1, iter: 175, c_loss: -21.24405002863157, g_loss: 10.531711479512783, sum_loss: -10.712338549118787\n",
            "epoch: 1, iter: 180, c_loss: -21.471187386629346, g_loss: 10.646469186930885, sum_loss: -10.824718199698461\n",
            "epoch: 1, iter: 185, c_loss: -21.716079215397308, g_loss: 10.764233943130957, sum_loss: -10.95184527226635\n",
            "epoch: 1, iter: 190, c_loss: -21.925804910798593, g_loss: 10.885853022052636, sum_loss: -11.039951888745957\n",
            "epoch: 1, iter: 195, c_loss: -22.191916827100066, g_loss: 11.00241856243013, sum_loss: -11.189498264669936\n",
            "epoch: 1, iter: 200, c_loss: -22.43180734875763, g_loss: 11.126859377267158, sum_loss: -11.304947971490472\n",
            "epoch: 1, iter: 205, c_loss: -22.656061760695998, g_loss: 11.240903490774409, sum_loss: -11.415158269921589\n",
            "epoch: 1, iter: 210, c_loss: -22.901544489247307, g_loss: 11.36050549662351, sum_loss: -11.541038992623797\n",
            "epoch: 1, iter: 215, c_loss: -23.15349467062071, g_loss: 11.480931572081099, sum_loss: -11.67256309853961\n",
            "epoch: 1, iter: 220, c_loss: -23.39100106225859, g_loss: 11.600058298540954, sum_loss: -11.790942763717634\n",
            "epoch: 1, iter: 225, c_loss: -23.63191318750834, g_loss: 11.719014946739314, sum_loss: -11.912898240769024\n",
            "epoch: 1, iter: 230, c_loss: -23.878379147264045, g_loss: 11.837204872080484, sum_loss: -12.041174275183561\n",
            "epoch: 1, iter: 235, c_loss: -24.110397722268313, g_loss: 11.961459913453464, sum_loss: -12.14893780881485\n",
            "epoch: 1, iter: 240, c_loss: -24.34924238110399, g_loss: 12.082211867811967, sum_loss: -12.267030513292024\n",
            "epoch: 1, iter: 245, c_loss: -24.59842171244276, g_loss: 12.202644818177705, sum_loss: -12.395776894265056\n",
            "epoch: 1, iter: 250, c_loss: -24.845400393030417, g_loss: 12.324196088454922, sum_loss: -12.521204304575495\n",
            "epoch: 1, iter: 255, c_loss: -25.07754159646596, g_loss: 12.443729208861251, sum_loss: -12.633812387604708\n",
            "epoch: 1, iter: 260, c_loss: -25.320802939168328, g_loss: 12.563659709651954, sum_loss: -12.757143229516373\n",
            "epoch: 1, iter: 265, c_loss: -25.56907314573945, g_loss: 12.684483831155067, sum_loss: -12.884589314584382\n",
            "epoch: 1, iter: 270, c_loss: -25.81133393961784, g_loss: 12.804184361985397, sum_loss: -13.007149577632442\n",
            "epoch: 1, iter: 275, c_loss: -26.05332722589359, g_loss: 12.928479232239104, sum_loss: -13.124847993654486\n",
            "epoch: 1, iter: 280, c_loss: -26.305225486747588, g_loss: 13.048014635655013, sum_loss: -13.257210851092575\n",
            "epoch: 1, iter: 285, c_loss: -26.543358358375706, g_loss: 13.166865229997288, sum_loss: -13.376493128378417\n",
            "epoch: 1, iter: 290, c_loss: -26.783070176636414, g_loss: 13.290993094034373, sum_loss: -13.49207708260204\n",
            "epoch: 1, iter: 295, c_loss: -27.03568872007368, g_loss: 13.412584049585114, sum_loss: -13.623104670488566\n",
            "epoch: 1, iter: 300, c_loss: -27.271248717296636, g_loss: 13.533058856874199, sum_loss: -13.738189860422438\n",
            "epoch: 1, iter: 305, c_loss: -27.520570218667608, g_loss: 13.654713910890461, sum_loss: -13.865856307777147\n",
            "epoch: 1, iter: 310, c_loss: -27.756778832577, g_loss: 13.780176041057237, sum_loss: -13.976602791519765\n",
            "epoch: 1, iter: 315, c_loss: -28.011139701170897, g_loss: 13.900842459672734, sum_loss: -14.110297241498163\n",
            "epoch: 1, iter: 320, c_loss: -28.25501974477035, g_loss: 14.019805156931037, sum_loss: -14.235214587839314\n",
            "epoch: 1, iter: 325, c_loss: -28.504855897434, g_loss: 14.147456719983573, sum_loss: -14.357399177450425\n",
            "epoch: 1, iter: 330, c_loss: -28.749560015548717, g_loss: 14.268133509505267, sum_loss: -14.48142650604345\n",
            "epoch: 1, iter: 335, c_loss: -28.99415699144685, g_loss: 14.391395855687362, sum_loss: -14.602761135759488\n",
            "epoch: 1, iter: 340, c_loss: -29.23633234979727, g_loss: 14.513615156093273, sum_loss: -14.722717193703996\n",
            "epoch: 1, iter: 345, c_loss: -29.48923822618455, g_loss: 14.636070935477203, sum_loss: -14.853167290707347\n",
            "epoch: 1, iter: 350, c_loss: -29.73692527834254, g_loss: 14.758889016234528, sum_loss: -14.978036262108011\n",
            "epoch: 1, iter: 355, c_loss: -29.973305931520628, g_loss: 14.88311002332507, sum_loss: -15.090195908195557\n",
            "epoch: 1, iter: 360, c_loss: -30.23431362693451, g_loss: 15.007405328173446, sum_loss: -15.226908298761066\n",
            "epoch: 1, iter: 365, c_loss: -30.47962068257426, g_loss: 15.127738701897714, sum_loss: -15.351881980676547\n",
            "epoch: 1, iter: 370, c_loss: -30.717295434259864, g_loss: 15.254779604375722, sum_loss: -15.462515829884142\n",
            "epoch: 1, iter: 375, c_loss: -30.977289166449793, g_loss: 15.377958492699975, sum_loss: -15.599330673749819\n",
            "epoch: 1, iter: 380, c_loss: -31.221498310474416, g_loss: 15.499907576273602, sum_loss: -15.721590734200815\n",
            "epoch: 1, iter: 385, c_loss: -31.473398022574834, g_loss: 15.6258120809667, sum_loss: -15.847585941608134\n",
            "epoch: 1, iter: 390, c_loss: -31.71864032454736, g_loss: 15.747416113259508, sum_loss: -15.97122421128785\n",
            "epoch: 1, iter: 395, c_loss: -31.96778893511189, g_loss: 15.872557960907036, sum_loss: -16.095230974204853\n",
            "epoch: 1, iter: 400, c_loss: -32.220795233698404, g_loss: 15.998220390559137, sum_loss: -16.222574843139267\n",
            "epoch: 1, iter: 405, c_loss: -32.46948025004362, g_loss: 16.12141897186026, sum_loss: -16.34806127818336\n",
            "epoch: 1, iter: 410, c_loss: -32.71426704365883, g_loss: 16.24445188053315, sum_loss: -16.46981516312568\n",
            "epoch: 1, iter: 415, c_loss: -32.97256998131055, g_loss: 16.371797011178895, sum_loss: -16.600772970131654\n",
            "epoch: 1, iter: 420, c_loss: -33.22265965575929, g_loss: 16.495645777063324, sum_loss: -16.727013878695963\n",
            "epoch: 1, iter: 425, c_loss: -33.46951441858417, g_loss: 16.621307708252978, sum_loss: -16.84820671033119\n",
            "epoch: 1, iter: 430, c_loss: -33.71696190247333, g_loss: 16.745160684707862, sum_loss: -16.971801217765467\n",
            "epoch: 1, iter: 435, c_loss: -33.96862073944155, g_loss: 16.870763015694347, sum_loss: -17.0978577237472\n",
            "epoch: 1, iter: 440, c_loss: -34.224581846592876, g_loss: 16.995656832755095, sum_loss: -17.22892501383778\n",
            "epoch: 1, iter: 445, c_loss: -34.47817267362505, g_loss: 17.12113662957197, sum_loss: -17.357036044053082\n",
            "epoch: 1, iter: 450, c_loss: -34.72210242158754, g_loss: 17.244111204734608, sum_loss: -17.477991216852935\n",
            "epoch: 1, iter: 455, c_loss: -34.97974960413019, g_loss: 17.371345891971707, sum_loss: -17.608403712158484\n",
            "epoch: 1, iter: 460, c_loss: -35.23158103050579, g_loss: 17.4970092665171, sum_loss: -17.734571763988686\n",
            "epoch: 1, iter: 465, c_loss: -35.48003823835212, g_loss: 17.622477332489403, sum_loss: -17.85756090586272\n",
            "epoch: 1, iter: 470, c_loss: -35.73262096865477, g_loss: 17.747923346249202, sum_loss: -17.98469762240557\n",
            "epoch: 1, iter: 475, c_loss: -35.99122674531864, g_loss: 17.874602517873658, sum_loss: -18.116624227444984\n",
            "epoch: 1, iter: 480, c_loss: -36.24351584225052, g_loss: 18.001104431499247, sum_loss: -18.24241141075127\n",
            "epoch: 1, iter: 485, c_loss: -36.49743633114218, g_loss: 18.129167800707243, sum_loss: -18.36826853043494\n",
            "epoch: 1, iter: 490, c_loss: -36.74834196586673, g_loss: 18.25453452339676, sum_loss: -18.49380744246997\n",
            "epoch: 1, iter: 495, c_loss: -37.00204448584714, g_loss: 18.377613487640673, sum_loss: -18.624430998206464\n",
            "epoch: 1, iter: 500, c_loss: -37.25705594751514, g_loss: 18.507504764716916, sum_loss: -18.749551182798225\n",
            "epoch: 1, iter: 505, c_loss: -37.514191382122775, g_loss: 18.635082548097078, sum_loss: -18.879108834025697\n",
            "epoch: 1, iter: 510, c_loss: -37.7669529252926, g_loss: 18.759849109608872, sum_loss: -19.007103815683728\n",
            "epoch: 1, iter: 515, c_loss: -38.01165384121033, g_loss: 18.88624723586371, sum_loss: -19.125406605346623\n",
            "epoch: 1, iter: 520, c_loss: -38.275699315233325, g_loss: 19.014423446606497, sum_loss: -19.26127586862683\n",
            "epoch: 1, iter: 525, c_loss: -38.532257298945495, g_loss: 19.140849289350417, sum_loss: -19.39140800959508\n",
            "epoch: 1, iter: 530, c_loss: -38.78673609575235, g_loss: 19.268138243710762, sum_loss: -19.51859785204159\n",
            "epoch: 1, iter: 535, c_loss: -39.044002047819774, g_loss: 19.39629679993699, sum_loss: -19.647705247882783\n",
            "epoch: 1, iter: 540, c_loss: -39.29773188247978, g_loss: 19.522882920092158, sum_loss: -19.774848962387622\n",
            "epoch: 1, iter: 545, c_loss: -39.552972631544385, g_loss: 19.650671295685143, sum_loss: -19.902301335859242\n",
            "epoch: 1, iter: 550, c_loss: -39.808093990448086, g_loss: 19.778367703361837, sum_loss: -20.02972628708625\n",
            "epoch: 1, iter: 560, c_loss: -40.32433521072102, g_loss: 20.0344413131792, sum_loss: -20.289893897541816\n",
            "epoch: 1, iter: 565, c_loss: -40.581205240006966, g_loss: 20.1607451960172, sum_loss: -20.420460043989767\n",
            "epoch: 1, iter: 570, c_loss: -40.83762560153477, g_loss: 20.288695289544055, sum_loss: -20.548930311990713\n",
            "epoch: 1, iter: 575, c_loss: -41.09417683476991, g_loss: 20.417931768456075, sum_loss: -20.676245066313836\n",
            "epoch: 1, iter: 580, c_loss: -41.35399689902094, g_loss: 20.546276331044282, sum_loss: -20.80772056797666\n",
            "epoch: 1, iter: 585, c_loss: -41.60632064572308, g_loss: 20.67414935065079, sum_loss: -20.93217129507229\n",
            "epoch: 1, iter: 590, c_loss: -41.86778050454578, g_loss: 20.80300346824119, sum_loss: -21.064777036304587\n",
            "epoch: 1, iter: 595, c_loss: -42.12521101422364, g_loss: 20.93169435231294, sum_loss: -21.193516661910696\n",
            "epoch: 1, iter: 600, c_loss: -42.37482503773473, g_loss: 21.060048187028084, sum_loss: -21.314776850706647\n",
            "epoch: 1, iter: 605, c_loss: -42.644818521649746, g_loss: 21.189740501738353, sum_loss: -21.455078019911394\n",
            "epoch: 1, iter: 610, c_loss: -42.89936518811011, g_loss: 21.316516183523042, sum_loss: -21.582849004587068\n",
            "epoch: 1, iter: 615, c_loss: -43.16098082359838, g_loss: 21.447429485646644, sum_loss: -21.713551337951735\n",
            "epoch: 1, iter: 620, c_loss: -43.420201124785336, g_loss: 21.576690164742622, sum_loss: -21.843510960042714\n",
            "epoch: 1, iter: 625, c_loss: -43.67875207900113, g_loss: 21.7059096250465, sum_loss: -21.97284245395463\n",
            "epoch: 1, iter: 630, c_loss: -43.937830255125036, g_loss: 21.833978556733978, sum_loss: -22.103851698391058\n",
            "epoch: 1, iter: 635, c_loss: -44.199606022638456, g_loss: 21.964356796850964, sum_loss: -22.23524922578749\n",
            "epoch: 1, iter: 640, c_loss: -44.45731662378162, g_loss: 22.09401305517619, sum_loss: -22.36330356860543\n",
            "epoch: 1, iter: 645, c_loss: -44.717882184815025, g_loss: 22.223551238069273, sum_loss: -22.49433094674575\n",
            "epoch: 1, iter: 650, c_loss: -44.97941997904253, g_loss: 22.352929735894822, sum_loss: -22.62649024314771\n",
            "epoch: 1, iter: 655, c_loss: -45.241572084938724, g_loss: 22.483337536427147, sum_loss: -22.758234548511577\n",
            "epoch: 1, iter: 660, c_loss: -45.50111032838997, g_loss: 22.61258526704897, sum_loss: -22.888525061341\n",
            "epoch: 1, iter: 665, c_loss: -45.762432038316554, g_loss: 22.7433280304943, sum_loss: -23.019104007822254\n",
            "epoch: 1, iter: 670, c_loss: -46.022891008650205, g_loss: 22.874148080733413, sum_loss: -23.148742927916793\n",
            "epoch: 1, iter: 675, c_loss: -46.278091041937216, g_loss: 23.004188897273398, sum_loss: -23.27390214466382\n",
            "epoch: 1, iter: 680, c_loss: -46.543054924732594, g_loss: 23.133093936453566, sum_loss: -23.40996098827903\n",
            "epoch: 1, iter: 685, c_loss: -46.80454924539381, g_loss: 23.264297737455312, sum_loss: -23.540251507938496\n",
            "epoch: 1, iter: 690, c_loss: -47.069355473084954, g_loss: 23.394803171104673, sum_loss: -23.67455230198028\n",
            "epoch: 1, iter: 695, c_loss: -47.330823215990634, g_loss: 23.525658781811817, sum_loss: -23.805164434178817\n",
            "epoch: 1, iter: 700, c_loss: -47.59535714222939, g_loss: 23.65652144569302, sum_loss: -23.93883569653637\n",
            "epoch: 1, iter: 705, c_loss: -47.85349404332761, g_loss: 23.78752445201419, sum_loss: -24.06596959131342\n",
            "epoch: 1, iter: 710, c_loss: -48.11878429019464, g_loss: 23.918420709609368, sum_loss: -24.20036358058527\n",
            "epoch: 1, iter: 715, c_loss: -48.38386951924107, g_loss: 24.04948302271006, sum_loss: -24.334386496531007\n",
            "epoch: 1, iter: 720, c_loss: -48.64593079694629, g_loss: 24.179547217797662, sum_loss: -24.466383579148626\n",
            "epoch: 1, iter: 725, c_loss: -48.90878074332882, g_loss: 24.31127897798032, sum_loss: -24.5975017653485\n",
            "epoch: 1, iter: 730, c_loss: -49.17527013052401, g_loss: 24.44395262792233, sum_loss: -24.731317502601684\n",
            "epoch: 1, iter: 735, c_loss: -49.43459457003655, g_loss: 24.574977331079083, sum_loss: -24.85961723895747\n",
            "epoch: 1, iter: 740, c_loss: -49.70200023817376, g_loss: 24.70564990890999, sum_loss: -24.99635032926377\n",
            "epoch: 1, iter: 745, c_loss: -49.96589058783582, g_loss: 24.8375635852994, sum_loss: -25.128327002536423\n",
            "epoch: 1, iter: 750, c_loss: -50.23230802791839, g_loss: 24.9705390903937, sum_loss: -25.261768937524693\n",
            "epoch: 1, iter: 755, c_loss: -50.497790972127014, g_loss: 25.102484731828625, sum_loss: -25.39530624029839\n",
            "epoch: 1, iter: 760, c_loss: -50.76090081438858, g_loss: 25.233625233081323, sum_loss: -25.527275581307254\n",
            "epoch: 1, iter: 765, c_loss: -51.02449203854216, g_loss: 25.364986296001664, sum_loss: -25.659505742540492\n",
            "epoch: 1, iter: 770, c_loss: -51.29081408106565, g_loss: 25.498251081500737, sum_loss: -25.79256299956491\n",
            "epoch: 1, iter: 775, c_loss: -51.55755263376433, g_loss: 25.63071048754464, sum_loss: -25.92684214621969\n",
            "epoch: 1, iter: 780, c_loss: -51.82114804577419, g_loss: 25.763242694189852, sum_loss: -26.057905351584335\n",
            "epoch: 1, iter: 785, c_loss: -52.087499643867346, g_loss: 25.89512702240152, sum_loss: -26.192372621465825\n",
            "epoch: 1, iter: 790, c_loss: -52.35485499514225, g_loss: 26.02795160065628, sum_loss: -26.326903394485967\n",
            "epoch: 1, iter: 795, c_loss: -52.62121764525328, g_loss: 26.159826855941407, sum_loss: -26.461390789311874\n",
            "epoch: 1, iter: 800, c_loss: -52.88757773741881, g_loss: 26.294356072373457, sum_loss: -26.593221665045352\n",
            "epoch: 1, iter: 805, c_loss: -53.15441615492453, g_loss: 26.426413457123058, sum_loss: -26.728002697801475\n",
            "epoch: 1, iter: 810, c_loss: -53.42148676768542, g_loss: 26.558824076140635, sum_loss: -26.862662691544788\n",
            "epoch: 1, iter: 815, c_loss: -53.689371182018355, g_loss: 26.69254003815022, sum_loss: -26.996831143868135\n",
            "epoch: 1, iter: 820, c_loss: -53.956359310129905, g_loss: 26.826210147471933, sum_loss: -27.130149162657972\n",
            "epoch: 1, iter: 825, c_loss: -54.224091532484024, g_loss: 26.958988776035188, sum_loss: -27.265102756448837\n",
            "epoch: 1, iter: 830, c_loss: -54.49040101491342, g_loss: 27.09040071821482, sum_loss: -27.400000296698597\n",
            "epoch: 1, iter: 835, c_loss: -54.75714872127806, g_loss: 27.225222959364167, sum_loss: -27.53192576191389\n",
            "epoch: 1, iter: 840, c_loss: -55.02886751439538, g_loss: 27.360279203804037, sum_loss: -27.668588310591343\n",
            "epoch: 1, iter: 845, c_loss: -55.296769313647964, g_loss: 27.493364662270626, sum_loss: -27.80340465137734\n",
            "epoch: 1, iter: 850, c_loss: -55.56396268279709, g_loss: 27.626521599220172, sum_loss: -27.937441083576918\n",
            "epoch: 1, iter: 855, c_loss: -55.83299554825928, g_loss: 27.76040653674739, sum_loss: -28.072589011511887\n",
            "epoch: 1, iter: 860, c_loss: -56.10154051353367, g_loss: 27.895185064946933, sum_loss: -28.206355448586738\n",
            "epoch: 1, iter: 865, c_loss: -56.365150214939774, g_loss: 28.02873438937306, sum_loss: -28.336415825566714\n",
            "epoch: 1, iter: 870, c_loss: -56.64178607835743, g_loss: 28.16341915844194, sum_loss: -28.478366919915487\n",
            "epoch: 1, iter: 875, c_loss: -56.91097616870998, g_loss: 28.297384262787627, sum_loss: -28.613591905922352\n",
            "epoch: 1, iter: 880, c_loss: -57.18047356483291, g_loss: 28.43189285924347, sum_loss: -28.74858070558944\n",
            "epoch: 1, iter: 885, c_loss: -57.44997039443659, g_loss: 28.567236278958745, sum_loss: -28.882734115477845\n",
            "epoch: 1, iter: 890, c_loss: -57.72057423209576, g_loss: 28.700558533469824, sum_loss: -29.020015698625933\n",
            "epoch: 1, iter: 895, c_loss: -57.98813862392589, g_loss: 28.835148642418893, sum_loss: -29.152989981506998\n",
            "epoch: 1, iter: 900, c_loss: -58.26135398571319, g_loss: 28.970747516614296, sum_loss: -29.290606469098897\n",
            "epoch: 1, iter: 905, c_loss: -58.44797863591092, g_loss: 29.106053442200768, sum_loss: -29.341925193710154\n",
            "epoch: 1, iter: 910, c_loss: -58.80411014314892, g_loss: 29.240004842232807, sum_loss: -29.56410530091611\n",
            "epoch: 1, iter: 915, c_loss: -59.07248481455541, g_loss: 29.374579464454104, sum_loss: -29.697905350101305\n",
            "epoch: 1, iter: 920, c_loss: -59.34633150352922, g_loss: 29.51079985965578, sum_loss: -29.83553164387344\n",
            "epoch: 1, iter: 925, c_loss: -59.616388221764666, g_loss: 29.646366592663632, sum_loss: -29.970021629101034\n",
            "epoch: 1, iter: 930, c_loss: -59.88891161942978, g_loss: 29.78105354124773, sum_loss: -30.107858078182048\n",
            "epoch: 1, iter: 935, c_loss: -60.15968978673462, g_loss: 29.916983840076306, sum_loss: -30.24270594665831\n",
            "epoch: 1, iter: 940, c_loss: -60.432966520383985, g_loss: 30.05266630711247, sum_loss: -30.380300213271514\n",
            "epoch: 1, iter: 945, c_loss: -60.70521570541773, g_loss: 30.188430978648576, sum_loss: -30.516784726769153\n",
            "epoch: 1, iter: 950, c_loss: -60.97698559764437, g_loss: 30.32340132093601, sum_loss: -30.65358427670836\n",
            "epoch: 1, iter: 955, c_loss: -61.251070630130975, g_loss: 30.460540249436026, sum_loss: -30.79053038069495\n",
            "epoch: 1, iter: 960, c_loss: -61.52417985219999, g_loss: 30.595519506068136, sum_loss: -30.928660346131856\n",
            "epoch: 1, iter: 965, c_loss: -61.795323301643805, g_loss: 30.731017600338653, sum_loss: -31.064305701305152\n",
            "epoch: 1, iter: 970, c_loss: -62.07017561453945, g_loss: 30.868018579787297, sum_loss: -31.202157034752155\n",
            "epoch: 1, iter: 975, c_loss: -62.343883635112114, g_loss: 31.004457497110213, sum_loss: -31.3394261380019\n",
            "epoch: 1, iter: 980, c_loss: -62.61667153919842, g_loss: 31.13975918293037, sum_loss: -31.476912356268052\n",
            "epoch: 1, iter: 985, c_loss: -62.8906730313345, g_loss: 31.276882336732168, sum_loss: -31.613790694602333\n",
            "epoch: 1, iter: 990, c_loss: -63.15964690892295, g_loss: 31.413760492749134, sum_loss: -31.745886416173818\n",
            "epoch: 1, iter: 995, c_loss: -63.43863875031474, g_loss: 31.55063524596618, sum_loss: -31.888003504348557\n",
            "epoch: 1, iter: 1000, c_loss: -63.71264931900096, g_loss: 31.687015120547233, sum_loss: -32.02563419845373\n",
            "epoch: 1, iter: 1005, c_loss: -63.98851661626288, g_loss: 31.823328136456027, sum_loss: -32.16518847980685\n",
            "epoch: 1, iter: 1010, c_loss: -64.26367695993218, g_loss: 31.9609378457489, sum_loss: -32.30273911418328\n",
            "epoch: 1, iter: 1015, c_loss: -64.53821689731541, g_loss: 32.09797525184585, sum_loss: -32.440241645469555\n",
            "epoch: 1, iter: 1020, c_loss: -64.81412080817606, g_loss: 32.23469882695623, sum_loss: -32.579421981219824\n",
            "epoch: 1, iter: 1025, c_loss: -65.0886055038748, g_loss: 32.37171931620467, sum_loss: -32.716886187670134\n",
            "epoch: 1, iter: 1030, c_loss: -65.36440780915675, g_loss: 32.50955361442158, sum_loss: -32.85485419473517\n",
            "epoch: 1, iter: 1035, c_loss: -65.64054593848024, g_loss: 32.646296693318114, sum_loss: -32.99424924516213\n",
            "epoch: 1, iter: 1040, c_loss: -65.91656779502952, g_loss: 32.78456309313028, sum_loss: -33.13200470189924\n",
            "epoch: 1, iter: 1045, c_loss: -66.19417555705058, g_loss: 32.92303587072617, sum_loss: -33.27113968632442\n",
            "epoch: 1, iter: 1050, c_loss: -66.46947381693292, g_loss: 33.06045305587287, sum_loss: -33.40902076106005\n",
            "epoch: 1, iter: 1055, c_loss: -66.74617477288558, g_loss: 33.19812377601463, sum_loss: -33.54805099687095\n",
            "epoch: 1, iter: 1060, c_loss: -67.02329630615701, g_loss: 33.335107408940374, sum_loss: -33.688188897216634\n",
            "epoch: 1, iter: 1065, c_loss: -67.2989451771951, g_loss: 33.47327470499381, sum_loss: -33.82567047220128\n",
            "epoch: 1, iter: 1070, c_loss: -67.57679495872421, g_loss: 33.61147831905748, sum_loss: -33.965316639666725\n",
            "epoch: 1, iter: 1075, c_loss: -67.85443423296792, g_loss: 33.75071320637168, sum_loss: -34.10372102659624\n",
            "epoch: 1, iter: 1080, c_loss: -68.13176751250144, g_loss: 33.88845442682805, sum_loss: -34.24331308567339\n",
            "epoch: 1, iter: 1085, c_loss: -68.41009168676426, g_loss: 34.0270729461414, sum_loss: -34.38301874062286\n",
            "epoch: 1, iter: 1090, c_loss: -68.68814235138709, g_loss: 34.16542011302098, sum_loss: -34.52272223836611\n",
            "Epoch 1 completed. Accuracy: None\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Critic.npy\n",
            "epoch: 2, iter: 0, c_loss: -68.96684789194748, g_loss: 34.303603916840366, sum_loss: -34.663243975107115\n",
            "epoch: 2, iter: 5, c_loss: -69.24029127204844, g_loss: 34.44225494234956, sum_loss: -34.79803632969888\n",
            "epoch: 2, iter: 10, c_loss: -69.5230973923945, g_loss: 34.58169139302475, sum_loss: -34.941405999369756\n",
            "epoch: 2, iter: 15, c_loss: -69.80310829729171, g_loss: 34.720364686253774, sum_loss: -35.08274361103794\n",
            "epoch: 2, iter: 20, c_loss: -70.08203150369414, g_loss: 34.85993897054134, sum_loss: -35.2220925331528\n",
            "epoch: 2, iter: 25, c_loss: -70.36136106012253, g_loss: 34.998096706396616, sum_loss: -35.36326435372592\n",
            "epoch: 2, iter: 30, c_loss: -70.63721372504233, g_loss: 35.13622966195314, sum_loss: -35.50098406308919\n",
            "epoch: 2, iter: 35, c_loss: -70.9197721184647, g_loss: 35.27696310416961, sum_loss: -35.642809014295096\n",
            "epoch: 2, iter: 40, c_loss: -71.19857947863255, g_loss: 35.416665600805196, sum_loss: -35.78191387782736\n",
            "epoch: 2, iter: 45, c_loss: -71.48019582315197, g_loss: 35.55524621874509, sum_loss: -35.92494960440688\n",
            "epoch: 2, iter: 50, c_loss: -71.74363597913366, g_loss: 35.695189376470815, sum_loss: -36.04844660266284\n",
            "epoch: 2, iter: 55, c_loss: -72.03767505334275, g_loss: 35.83460836479351, sum_loss: -36.20306668854924\n",
            "epoch: 2, iter: 60, c_loss: -72.31955068576212, g_loss: 35.974265211274634, sum_loss: -36.34528547448749\n",
            "epoch: 2, iter: 65, c_loss: -72.6025570378498, g_loss: 36.115108923337424, sum_loss: -36.48744811451238\n",
            "epoch: 2, iter: 70, c_loss: -72.84196643393867, g_loss: 36.254130700500326, sum_loss: -36.58783573343834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-661b315a53e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mc_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mc_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/parameter.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, to)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_node_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backprop_op'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# executing the back-propagation operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/graph.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;31m# return (K.grad, x.grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'func'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'conv2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'backprop_op'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/graph.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                             \u001b[0mpad_x_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                     \u001b[0;31m# cutting the padded portion from the input-feature-map's gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2229\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}