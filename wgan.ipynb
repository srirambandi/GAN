{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "wgan.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirambandi/GAN/blob/master/wgan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk-FsI3wcrMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# when running in colab notebooks, first install library\n",
        "!pip install import-ai\n",
        "# upload respective dataset manually from examples directory of the library or download as below\n",
        "!apt install subversion\n",
        "!svn checkout https://github.com/srirambandi/ai/trunk/examples/MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bql-uXp0cqPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ai\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Unwx_Hc1cqPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_dim = 100\n",
        "gf_dim = 64\n",
        "df_dim = 64"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQzdpXIpcyL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ai.manual_seed(2357)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBgfrdNzcqPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(m):\n",
        "    train_dict = np.load('MNIST/train.npy', allow_pickle=True)\n",
        "    test_dict = np.load('MNIST/test.npy', allow_pickle=True)\n",
        "    data = np.concatenate([train_dict.item()['data'], test_dict.item()['data']])\n",
        "    data = data.transpose(1, 2, 0)   # making data batch-last\n",
        "    data = data.reshape(1, *data.shape) / 255   # adding channel dimension and normalizing data\n",
        "    epoch = 0\n",
        "    \n",
        "    while True:\n",
        "        epoch += 1\n",
        "        for batch in range(int(data.shape[-1] / m)):\n",
        "            yield data[...,batch * m:(batch + 1) * m], epoch"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juS9j_gScqPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(ai.Module):\n",
        "    def __init__(self):\n",
        "        self.g_fc = ai.Linear(z_dim, 8*gf_dim * 2 * 2)\n",
        "        self.g_bn1 = ai.BatchNorm((8*gf_dim, 2, 2))\n",
        "        self.g_deconv1 = ai.ConvTranspose2d(8*gf_dim, 4*gf_dim, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        self.g_bn2 = ai.BatchNorm((4*gf_dim, 4, 4))\n",
        "        self.g_deconv2 = ai.ConvTranspose2d(4*gf_dim, 2*gf_dim, kernel_size=5, stride=2, padding=2, a=0)\n",
        "        self.g_bn3 = ai.BatchNorm((2*gf_dim, 7, 7))\n",
        "        self.g_deconv3 = ai.ConvTranspose2d(2*gf_dim, gf_dim, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        self.g_bn4 = ai.BatchNorm((gf_dim, 14, 14))\n",
        "        self.g_deconv4 = ai.ConvTranspose2d(gf_dim, 1, kernel_size=5, stride=2, padding=2, a=1)\n",
        "        \n",
        "    def forward(self, z):\n",
        "        o1 = ai.G.reshape(self.g_fc(z), (8*gf_dim, 2, 2))\n",
        "        o2 = ai.G.relu(self.g_bn1(o1))\n",
        "        o3 = ai.G.relu(self.g_bn2(self.g_deconv1(o2)))\n",
        "        o4 = ai.G.relu(self.g_bn3(self.g_deconv2(o3)))\n",
        "        o5 = ai.G.relu(self.g_bn4(self.g_deconv3(o4)))\n",
        "        fake_image = ai.G.tanh(self.g_deconv4(o5))\n",
        "        return fake_image"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPElqs6gcqPl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Critic(ai.Module):\n",
        "    def __init__(self):\n",
        "        self.d_conv1 = ai.Conv2d(1, 64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_conv2 = ai.Conv2d(64, 2*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn1 = ai.BatchNorm((2*64, 7, 7))\n",
        "        self.d_conv3 = ai.Conv2d(2*64, 3*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn2 = ai.BatchNorm((3*64, 4, 4))\n",
        "        self.d_conv4 = ai.Conv2d(3*64, 4*64, kernel_size=5, stride=2, padding=2)\n",
        "        self.d_bn3 = ai.BatchNorm((4*64, 2, 2))\n",
        "        self.d_fc = ai.Linear(1024, 1)\n",
        "        \n",
        "    def forward(self, image):\n",
        "        o1 = ai.G.lrelu(self.d_conv1(image))\n",
        "        o2 = ai.G.lrelu(self.d_bn1(self.d_conv2(o1)))\n",
        "        o3 = ai.G.lrelu(self.d_bn2(self.d_conv3(o2)))\n",
        "        o4 = ai.G.lrelu(self.d_bn3(self.d_conv4(o3)))\n",
        "        o5 = self.d_fc(o4)\n",
        "        return o5"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50IAOgjXcqPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a6c1f9f4-bde2-4353-fd42-4c6766c21931"
      },
      "source": [
        "generator = Generator()\n",
        "critic = Critic()\n",
        "print(generator)\n",
        "print(critic)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  g_fc: Linear(input_features=100, output_features=2048, bias=True)\n",
            "  g_bn1: BatchNorm((512, 2, 2), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv1: ConvTranspose2d(512, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            "  g_bn2: BatchNorm((256, 4, 4), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv2: ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(0, 0), bias=True)\n",
            "  g_bn3: BatchNorm((128, 7, 7), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv3: ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            "  g_bn4: BatchNorm((64, 14, 14), axis=-1, momentum=0.9, bias=True)\n",
            "  g_deconv4: ConvTranspose2d(64, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), a=(1, 1), bias=True)\n",
            ")\n",
            "Critic(\n",
            "  d_conv1: Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_conv2: Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn1: BatchNorm((128, 7, 7), axis=-1, momentum=0.9, bias=True)\n",
            "  d_conv3: Conv2d(128, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn2: BatchNorm((192, 4, 4), axis=-1, momentum=0.9, bias=True)\n",
            "  d_conv4: Conv2d(192, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=True)\n",
            "  d_bn3: BatchNorm((256, 2, 2), axis=-1, momentum=0.9, bias=True)\n",
            "  d_fc: Linear(input_features=1024, output_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYbbyJZBcqPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 0.00005\n",
        "c = 0.01\n",
        "g_optim = ai.Optimizer(generator.parameters(), optim_fn='RMSProp', lr=lr)\n",
        "c_optim = ai.Optimizer(critic.parameters(), optim_fn='RMSProp', lr=lr)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRh7R4j1cqP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it, epoch = 0, 0\n",
        "m = 64   # batch size\n",
        "n_critic = 5   # number of critic updates per generator update\n",
        "c = 0.01  # clip value for critic weigthts after each update\n",
        "\n",
        "batch_size = ai.Parameter((1, 1), init_ones=True, constant=float(m), eval_grad=False)   # batch size 'm' as a Parameter constant\n",
        "neg_ones = ai.Parameter((1, 1), init_ones=True, constant=-1.0, eval_grad=False)\n",
        "\n",
        "# real images data generator\n",
        "data = data_generator(m)\n",
        "\n",
        "sample_z = np.random.randn(z_dim, m)\n",
        "sample_images = None"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLpbkD0LcqP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampler(sample_images):\n",
        "    ai.G.grad_mode = False\n",
        "\n",
        "    # generate images like real data\n",
        "    fake_images = generator.forward(sample_z).data\n",
        "    fake_images = (fake_images + 1.) / 2.\n",
        "\n",
        "    if sample_images is not None:\n",
        "        sample_images = np.concatenate([sample_images, fake_images], axis=-1)\n",
        "    else:\n",
        "        sample_images = fake_images\n",
        "\n",
        "    np.save('sample_images.npy', sample_images)\n",
        "    \n",
        "    ai.G.grad_mode = True"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKaygbefcqQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "148c99b6-4276-4cd0-f440-05599e9bd29d"
      },
      "source": [
        "for it in range(10000):\n",
        "\n",
        "    # freeze generator before optimizing critic\n",
        "    for p in generator.parameters():\n",
        "        p.eval_grad = False\n",
        "\n",
        "    critic_iter = 100 if it < 25 or it%500 == 0 else n_critic\n",
        "\n",
        "    # training critic to identify real/fake data\n",
        "    for _ in range(critic_iter):\n",
        "\n",
        "        real_images, epoch = data.__next__()\n",
        "        if (real_images.shape[-1] != m):\n",
        "            continue\n",
        "\n",
        "        c_loss_real = critic.forward(real_images)\n",
        "\n",
        "        z = np.random.randn(z_dim, m)\n",
        "        fake_images = generator.forward(z)\n",
        "\n",
        "        c_loss_fake = critic.forward(fake_images)\n",
        "\n",
        "        # add the above two losses and reduce their mean\n",
        "        c_loss = c_loss_fake - c_loss_real\n",
        "        c_loss = ai.G.sum(c_loss)\n",
        "        c_loss = c_loss / batch_size\n",
        "        c_loss.grad = np.ones(c_loss.shape)\n",
        "\n",
        "        c_loss.backward()\n",
        "        c_optim.step()\n",
        "        c_optim.zero_grad()\n",
        "\n",
        "        ai.clip_grad_value(critic.parameters(), c)\n",
        "\n",
        "    # unfreeze generator\n",
        "    for p in generator.parameters():\n",
        "        p.eval_grad = True\n",
        "\n",
        "    # training generator to fool critic with fake data\n",
        "    z = np.random.randn(z_dim, m)\n",
        "    fake_images = generator.forward(z)\n",
        "\n",
        "    g_loss = critic.forward(fake_images)\n",
        "    g_loss = ai.G.sum(g_loss)\n",
        "    g_loss = g_loss / batch_size\n",
        "    g_loss = neg_ones * g_loss\n",
        "    g_loss.grad = np.ones(g_loss.shape)\n",
        "\n",
        "    g_loss.backward()\n",
        "    g_optim.step()\n",
        "    g_optim.zero_grad()\n",
        "    c_optim.zero_grad()\n",
        "\n",
        "    if it%10 == 0:\n",
        "        print('Iter: {}, Epoch: {}, c_loss: {}, g_loss: {}'.format(it, epoch, c_loss.data[0, 0], g_loss.data[0, 0]))\n",
        "    \n",
        "    if it%100 == 0:\n",
        "        sampler(sample_images)\n",
        "        generator.save()\n",
        "        critic.save()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using RMSProp\n",
            "using RMSProp\n",
            "Iter: 0, Epoch: 1, c_loss: -0.9580079326771251, g_loss: 0.9809650282421694\n",
            "saving model...\n",
            "Successfully saved model in Generator.npy\n",
            "saving model...\n",
            "Successfully saved model in Critic.npy\n",
            "Iter: 10, Epoch: 2, c_loss: -14.890187472690009, g_loss: 10.35686618968698\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-735efa368429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mc_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mc_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mc_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/parameter.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, grad, to)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_node_id\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'backprop_op'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m       \u001b[0;31m# executing the back-propagation operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/graph.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;31m# return (K.grad, x.grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'func'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'conv2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outputs'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'backprop_op'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ai/graph.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                             \u001b[0mpad_x_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                     \u001b[0;31m# cutting the padded portion from the input-feature-map's gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2229\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}